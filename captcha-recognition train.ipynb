{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "captcha.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLwJ1I8lu0_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "from fastai.vision import Path\n",
        "import torch\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X2_lkdHvDEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "270475c2-bbb6-48cf-8e59-e360d75606ae"
      },
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6AxXJX2vMaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(a):\n",
        "    onehot = [0]*ALL_CHAR_SET_LEN\n",
        "    idx = ALL_CHAR_SET.index(a)\n",
        "    onehot[idx] += 1\n",
        "    return onehot"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAzUeQQKz-Kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "ALPHABET = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "ALL_CHAR_SET = NUMBER + ALPHABET\n",
        "ALL_CHAR_SET_LEN = len(ALL_CHAR_SET)\n",
        "MAX_CAPTCHA = 5"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlfu2txsxbii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mydataset(Dataset):\n",
        "    def __init__(self, path, is_train=True, transform=None):\n",
        "        self.path = path\n",
        "        if is_train: self.img = os.listdir(self.path)[:1000]\n",
        "        else: self.img = os.listdir(self.path)[1001:]\n",
        "        try: self.img.remove('3bnfnd.png')\n",
        "        except: pass\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img[idx]\n",
        "        img = Image.open(self.path/img_path)\n",
        "        img = img.convert('L')\n",
        "        label = Path(self.path/img_path).name[:-4]\n",
        "        label_oh = []\n",
        "        for i in label:\n",
        "            label_oh += encode(i)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, np.array(label_oh), label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.img)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_1LooeLyGsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d4024a6-9e37-4e7f-cbd7-f7ba11fc96cb"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = '/captcha.zip'\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdbiN5JSzYkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize([224, 224]),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "train_ds = Mydataset(Path('/content/samples/samples'), transform=transform)\n",
        "test_ds = Mydataset(Path('/content/samples/samples'), False, transform)\n",
        "train_dl = DataLoader(train_ds, batch_size=64, num_workers=0)\n",
        "test_dl = DataLoader(train_ds, batch_size=1, num_workers=0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk9gyQsKznLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4fcb31aa-a62d-4bbc-e4f5-c2dc0a21df4a"
      },
      "source": [
        "model = models.resnet18(pretrained=False)\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "model.fc = nn.Linear(in_features=512, out_features=ALL_CHAR_SET_LEN*MAX_CAPTCHA, bias=True)\n",
        "model.to(device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=180, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBKStyWz0JVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.MultiLabelSoftMarginLoss()\n",
        "optm = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9pvxIJf0Mf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e1451b38-e94c-485b-ae60-d3621d71fdbf"
      },
      "source": [
        "hist={'epochloss':[],'trainacc':[],'testacc':[]}\n",
        "minl=10000\n",
        "modelname='captcharesnet'\n",
        "for epoch in range(40):\n",
        "    lossval=[]\n",
        "    for step, i in enumerate(train_dl):\n",
        "        img, label_oh, label = i\n",
        "        img = Variable(img).cuda()\n",
        "        label_oh = Variable(label_oh.float()).cuda()\n",
        "        pred = model(img)\n",
        "        loss = loss_func(pred, label_oh)\n",
        "        lossval.append(loss.item())\n",
        "        optm.zero_grad()\n",
        "        loss.backward()\n",
        "        optm.step()\n",
        "        print('eopch:', epoch+1, 'step:', step+1, 'loss:', loss.item())\n",
        "    curr_epoch_loss=np.array(lossval).mean()\n",
        "    if curr_epoch_loss<minl:\n",
        "      minl=curr_epoch_loss\n",
        "      bestmodel=model.state_dict()\n",
        "    curr_epoch_loss=np.array(lossval).mean()\n",
        "    hist['epochloss'].append(curr_epoch_loss)\n",
        "torch.save(bestmodel,'{0}_{1:0.4f}.pth'.format(modelname,minl))\n",
        "        "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eopch: 1 step: 1 loss: 0.07529532164335251\n",
            "eopch: 1 step: 2 loss: 0.07121072709560394\n",
            "eopch: 1 step: 3 loss: 0.0686471164226532\n",
            "eopch: 1 step: 4 loss: 0.06932112574577332\n",
            "eopch: 1 step: 5 loss: 0.06654561311006546\n",
            "eopch: 1 step: 6 loss: 0.07080364227294922\n",
            "eopch: 1 step: 7 loss: 0.0714176669716835\n",
            "eopch: 1 step: 8 loss: 0.06543561816215515\n",
            "eopch: 1 step: 9 loss: 0.068722203373909\n",
            "eopch: 1 step: 10 loss: 0.06956450641155243\n",
            "eopch: 1 step: 11 loss: 0.07022838294506073\n",
            "eopch: 1 step: 12 loss: 0.0643436536192894\n",
            "eopch: 1 step: 13 loss: 0.06548964232206345\n",
            "eopch: 1 step: 14 loss: 0.06337521225214005\n",
            "eopch: 1 step: 15 loss: 0.06812246888875961\n",
            "eopch: 1 step: 16 loss: 0.05322299525141716\n",
            "eopch: 2 step: 1 loss: 0.06528767198324203\n",
            "eopch: 2 step: 2 loss: 0.059424594044685364\n",
            "eopch: 2 step: 3 loss: 0.061092764139175415\n",
            "eopch: 2 step: 4 loss: 0.06147482991218567\n",
            "eopch: 2 step: 5 loss: 0.05585820972919464\n",
            "eopch: 2 step: 6 loss: 0.06304396688938141\n",
            "eopch: 2 step: 7 loss: 0.06333392858505249\n",
            "eopch: 2 step: 8 loss: 0.05581246688961983\n",
            "eopch: 2 step: 9 loss: 0.06003272533416748\n",
            "eopch: 2 step: 10 loss: 0.05931079387664795\n",
            "eopch: 2 step: 11 loss: 0.068949393928051\n",
            "eopch: 2 step: 12 loss: 0.05824798345565796\n",
            "eopch: 2 step: 13 loss: 0.06252492219209671\n",
            "eopch: 2 step: 14 loss: 0.05731634795665741\n",
            "eopch: 2 step: 15 loss: 0.06605030596256256\n",
            "eopch: 2 step: 16 loss: 0.050855036824941635\n",
            "eopch: 3 step: 1 loss: 0.06274247169494629\n",
            "eopch: 3 step: 2 loss: 0.05409317836165428\n",
            "eopch: 3 step: 3 loss: 0.04953587427735329\n",
            "eopch: 3 step: 4 loss: 0.05261740833520889\n",
            "eopch: 3 step: 5 loss: 0.04996607452630997\n",
            "eopch: 3 step: 6 loss: 0.055698614567518234\n",
            "eopch: 3 step: 7 loss: 0.05218306928873062\n",
            "eopch: 3 step: 8 loss: 0.05136534944176674\n",
            "eopch: 3 step: 9 loss: 0.050959233194589615\n",
            "eopch: 3 step: 10 loss: 0.05324099585413933\n",
            "eopch: 3 step: 11 loss: 0.05108337849378586\n",
            "eopch: 3 step: 12 loss: 0.05270664393901825\n",
            "eopch: 3 step: 13 loss: 0.050768185406923294\n",
            "eopch: 3 step: 14 loss: 0.050096359103918076\n",
            "eopch: 3 step: 15 loss: 0.052794259041547775\n",
            "eopch: 3 step: 16 loss: 0.038902509957551956\n",
            "eopch: 4 step: 1 loss: 0.05368894338607788\n",
            "eopch: 4 step: 2 loss: 0.045854076743125916\n",
            "eopch: 4 step: 3 loss: 0.04302161559462547\n",
            "eopch: 4 step: 4 loss: 0.043182551860809326\n",
            "eopch: 4 step: 5 loss: 0.04036661237478256\n",
            "eopch: 4 step: 6 loss: 0.05009351670742035\n",
            "eopch: 4 step: 7 loss: 0.04133789241313934\n",
            "eopch: 4 step: 8 loss: 0.037512537091970444\n",
            "eopch: 4 step: 9 loss: 0.044554322957992554\n",
            "eopch: 4 step: 10 loss: 0.046894386410713196\n",
            "eopch: 4 step: 11 loss: 0.043207645416259766\n",
            "eopch: 4 step: 12 loss: 0.04357415437698364\n",
            "eopch: 4 step: 13 loss: 0.039397403597831726\n",
            "eopch: 4 step: 14 loss: 0.037704452872276306\n",
            "eopch: 4 step: 15 loss: 0.04414784535765648\n",
            "eopch: 4 step: 16 loss: 0.026128113269805908\n",
            "eopch: 5 step: 1 loss: 0.04052427411079407\n",
            "eopch: 5 step: 2 loss: 0.035069338977336884\n",
            "eopch: 5 step: 3 loss: 0.03352056443691254\n",
            "eopch: 5 step: 4 loss: 0.039803750813007355\n",
            "eopch: 5 step: 5 loss: 0.035463519394397736\n",
            "eopch: 5 step: 6 loss: 0.03238343447446823\n",
            "eopch: 5 step: 7 loss: 0.032667674124240875\n",
            "eopch: 5 step: 8 loss: 0.03472776710987091\n",
            "eopch: 5 step: 9 loss: 0.033595673739910126\n",
            "eopch: 5 step: 10 loss: 0.035194963216781616\n",
            "eopch: 5 step: 11 loss: 0.03730233758687973\n",
            "eopch: 5 step: 12 loss: 0.03229622542858124\n",
            "eopch: 5 step: 13 loss: 0.030549725517630577\n",
            "eopch: 5 step: 14 loss: 0.035471100360155106\n",
            "eopch: 5 step: 15 loss: 0.03286740183830261\n",
            "eopch: 5 step: 16 loss: 0.022860174998641014\n",
            "eopch: 6 step: 1 loss: 0.04169410467147827\n",
            "eopch: 6 step: 2 loss: 0.030330609530210495\n",
            "eopch: 6 step: 3 loss: 0.029024630784988403\n",
            "eopch: 6 step: 4 loss: 0.03289322182536125\n",
            "eopch: 6 step: 5 loss: 0.029345743358135223\n",
            "eopch: 6 step: 6 loss: 0.03199562057852745\n",
            "eopch: 6 step: 7 loss: 0.032421715557575226\n",
            "eopch: 6 step: 8 loss: 0.028045862913131714\n",
            "eopch: 6 step: 9 loss: 0.028946902602910995\n",
            "eopch: 6 step: 10 loss: 0.031622253358364105\n",
            "eopch: 6 step: 11 loss: 0.03134256228804588\n",
            "eopch: 6 step: 12 loss: 0.029437623918056488\n",
            "eopch: 6 step: 13 loss: 0.022906670346856117\n",
            "eopch: 6 step: 14 loss: 0.02498498745262623\n",
            "eopch: 6 step: 15 loss: 0.029136355966329575\n",
            "eopch: 6 step: 16 loss: 0.015847960487008095\n",
            "eopch: 7 step: 1 loss: 0.02917839214205742\n",
            "eopch: 7 step: 2 loss: 0.025522153824567795\n",
            "eopch: 7 step: 3 loss: 0.020329948514699936\n",
            "eopch: 7 step: 4 loss: 0.026107562705874443\n",
            "eopch: 7 step: 5 loss: 0.017854291945695877\n",
            "eopch: 7 step: 6 loss: 0.019928641617298126\n",
            "eopch: 7 step: 7 loss: 0.023927686735987663\n",
            "eopch: 7 step: 8 loss: 0.021659381687641144\n",
            "eopch: 7 step: 9 loss: 0.028072331100702286\n",
            "eopch: 7 step: 10 loss: 0.023049164563417435\n",
            "eopch: 7 step: 11 loss: 0.03031351789832115\n",
            "eopch: 7 step: 12 loss: 0.025049200281500816\n",
            "eopch: 7 step: 13 loss: 0.02198566123843193\n",
            "eopch: 7 step: 14 loss: 0.02294648066163063\n",
            "eopch: 7 step: 15 loss: 0.020623404532670975\n",
            "eopch: 7 step: 16 loss: 0.010917137376964092\n",
            "eopch: 8 step: 1 loss: 0.024733440950512886\n",
            "eopch: 8 step: 2 loss: 0.022636190056800842\n",
            "eopch: 8 step: 3 loss: 0.020535271614789963\n",
            "eopch: 8 step: 4 loss: 0.015599398873746395\n",
            "eopch: 8 step: 5 loss: 0.017983535304665565\n",
            "eopch: 8 step: 6 loss: 0.02098064497113228\n",
            "eopch: 8 step: 7 loss: 0.0232316292822361\n",
            "eopch: 8 step: 8 loss: 0.01787150651216507\n",
            "eopch: 8 step: 9 loss: 0.019136041402816772\n",
            "eopch: 8 step: 10 loss: 0.020732909440994263\n",
            "eopch: 8 step: 11 loss: 0.022420238703489304\n",
            "eopch: 8 step: 12 loss: 0.01598166674375534\n",
            "eopch: 8 step: 13 loss: 0.019870109856128693\n",
            "eopch: 8 step: 14 loss: 0.01548802200704813\n",
            "eopch: 8 step: 15 loss: 0.021102305501699448\n",
            "eopch: 8 step: 16 loss: 0.01066884770989418\n",
            "eopch: 9 step: 1 loss: 0.024318836629390717\n",
            "eopch: 9 step: 2 loss: 0.016775988042354584\n",
            "eopch: 9 step: 3 loss: 0.021268576383590698\n",
            "eopch: 9 step: 4 loss: 0.01706080511212349\n",
            "eopch: 9 step: 5 loss: 0.018007684499025345\n",
            "eopch: 9 step: 6 loss: 0.014894114807248116\n",
            "eopch: 9 step: 7 loss: 0.014549192041158676\n",
            "eopch: 9 step: 8 loss: 0.014199672266840935\n",
            "eopch: 9 step: 9 loss: 0.021402325481176376\n",
            "eopch: 9 step: 10 loss: 0.01880013942718506\n",
            "eopch: 9 step: 11 loss: 0.01600618287920952\n",
            "eopch: 9 step: 12 loss: 0.01722392998635769\n",
            "eopch: 9 step: 13 loss: 0.021187715232372284\n",
            "eopch: 9 step: 14 loss: 0.018268432468175888\n",
            "eopch: 9 step: 15 loss: 0.01655225083231926\n",
            "eopch: 9 step: 16 loss: 0.00756948022171855\n",
            "eopch: 10 step: 1 loss: 0.017418071627616882\n",
            "eopch: 10 step: 2 loss: 0.015957225114107132\n",
            "eopch: 10 step: 3 loss: 0.016571179032325745\n",
            "eopch: 10 step: 4 loss: 0.013297156430780888\n",
            "eopch: 10 step: 5 loss: 0.012361062690615654\n",
            "eopch: 10 step: 6 loss: 0.01397744845598936\n",
            "eopch: 10 step: 7 loss: 0.016099046915769577\n",
            "eopch: 10 step: 8 loss: 0.012791602872312069\n",
            "eopch: 10 step: 9 loss: 0.011668041348457336\n",
            "eopch: 10 step: 10 loss: 0.012899508699774742\n",
            "eopch: 10 step: 11 loss: 0.014764145016670227\n",
            "eopch: 10 step: 12 loss: 0.014931533485651016\n",
            "eopch: 10 step: 13 loss: 0.013808251358568668\n",
            "eopch: 10 step: 14 loss: 0.015016499906778336\n",
            "eopch: 10 step: 15 loss: 0.011418906040489674\n",
            "eopch: 10 step: 16 loss: 0.008690445683896542\n",
            "eopch: 11 step: 1 loss: 0.011053393594920635\n",
            "eopch: 11 step: 2 loss: 0.01245931163430214\n",
            "eopch: 11 step: 3 loss: 0.01018504612147808\n",
            "eopch: 11 step: 4 loss: 0.014182963408529758\n",
            "eopch: 11 step: 5 loss: 0.01647607423365116\n",
            "eopch: 11 step: 6 loss: 0.014156825840473175\n",
            "eopch: 11 step: 7 loss: 0.013029607944190502\n",
            "eopch: 11 step: 8 loss: 0.012902439571917057\n",
            "eopch: 11 step: 9 loss: 0.008892642334103584\n",
            "eopch: 11 step: 10 loss: 0.013814846985042095\n",
            "eopch: 11 step: 11 loss: 0.014259550720453262\n",
            "eopch: 11 step: 12 loss: 0.012710521928966045\n",
            "eopch: 11 step: 13 loss: 0.013210237957537174\n",
            "eopch: 11 step: 14 loss: 0.013623129576444626\n",
            "eopch: 11 step: 15 loss: 0.014340980909764767\n",
            "eopch: 11 step: 16 loss: 0.00821917038410902\n",
            "eopch: 12 step: 1 loss: 0.011808834969997406\n",
            "eopch: 12 step: 2 loss: 0.011626970022916794\n",
            "eopch: 12 step: 3 loss: 0.010338705964386463\n",
            "eopch: 12 step: 4 loss: 0.009453274309635162\n",
            "eopch: 12 step: 5 loss: 0.010468396358191967\n",
            "eopch: 12 step: 6 loss: 0.01445350144058466\n",
            "eopch: 12 step: 7 loss: 0.01037933211773634\n",
            "eopch: 12 step: 8 loss: 0.009191002696752548\n",
            "eopch: 12 step: 9 loss: 0.009463230147957802\n",
            "eopch: 12 step: 10 loss: 0.010788879357278347\n",
            "eopch: 12 step: 11 loss: 0.01032593846321106\n",
            "eopch: 12 step: 12 loss: 0.01443490944802761\n",
            "eopch: 12 step: 13 loss: 0.014973224140703678\n",
            "eopch: 12 step: 14 loss: 0.01122291013598442\n",
            "eopch: 12 step: 15 loss: 0.012703416869044304\n",
            "eopch: 12 step: 16 loss: 0.00684877997264266\n",
            "eopch: 13 step: 1 loss: 0.009168829768896103\n",
            "eopch: 13 step: 2 loss: 0.008399276062846184\n",
            "eopch: 13 step: 3 loss: 0.006672927178442478\n",
            "eopch: 13 step: 4 loss: 0.005309038795530796\n",
            "eopch: 13 step: 5 loss: 0.009104731492698193\n",
            "eopch: 13 step: 6 loss: 0.00957830622792244\n",
            "eopch: 13 step: 7 loss: 0.011262110434472561\n",
            "eopch: 13 step: 8 loss: 0.00807854626327753\n",
            "eopch: 13 step: 9 loss: 0.0077578104101121426\n",
            "eopch: 13 step: 10 loss: 0.007010468281805515\n",
            "eopch: 13 step: 11 loss: 0.007559080608189106\n",
            "eopch: 13 step: 12 loss: 0.009142476134002209\n",
            "eopch: 13 step: 13 loss: 0.0067961434833705425\n",
            "eopch: 13 step: 14 loss: 0.009525778703391552\n",
            "eopch: 13 step: 15 loss: 0.008185230195522308\n",
            "eopch: 13 step: 16 loss: 0.006906974595040083\n",
            "eopch: 14 step: 1 loss: 0.0075468216091394424\n",
            "eopch: 14 step: 2 loss: 0.005284360609948635\n",
            "eopch: 14 step: 3 loss: 0.006415861658751965\n",
            "eopch: 14 step: 4 loss: 0.004834403283894062\n",
            "eopch: 14 step: 5 loss: 0.007056244648993015\n",
            "eopch: 14 step: 6 loss: 0.00610450841486454\n",
            "eopch: 14 step: 7 loss: 0.008768483996391296\n",
            "eopch: 14 step: 8 loss: 0.007408034056425095\n",
            "eopch: 14 step: 9 loss: 0.00779793132096529\n",
            "eopch: 14 step: 10 loss: 0.008545110933482647\n",
            "eopch: 14 step: 11 loss: 0.004442133940756321\n",
            "eopch: 14 step: 12 loss: 0.005255476571619511\n",
            "eopch: 14 step: 13 loss: 0.008647525683045387\n",
            "eopch: 14 step: 14 loss: 0.010708943009376526\n",
            "eopch: 14 step: 15 loss: 0.009735947474837303\n",
            "eopch: 14 step: 16 loss: 0.004404730629175901\n",
            "eopch: 15 step: 1 loss: 0.009730897843837738\n",
            "eopch: 15 step: 2 loss: 0.009067917242646217\n",
            "eopch: 15 step: 3 loss: 0.008267117664217949\n",
            "eopch: 15 step: 4 loss: 0.006599311716854572\n",
            "eopch: 15 step: 5 loss: 0.006102077662944794\n",
            "eopch: 15 step: 6 loss: 0.00966451596468687\n",
            "eopch: 15 step: 7 loss: 0.008274678140878677\n",
            "eopch: 15 step: 8 loss: 0.007779478095471859\n",
            "eopch: 15 step: 9 loss: 0.012108378112316132\n",
            "eopch: 15 step: 10 loss: 0.011620648205280304\n",
            "eopch: 15 step: 11 loss: 0.00624803127720952\n",
            "eopch: 15 step: 12 loss: 0.007271857000887394\n",
            "eopch: 15 step: 13 loss: 0.0074261752888560295\n",
            "eopch: 15 step: 14 loss: 0.009026734158396721\n",
            "eopch: 15 step: 15 loss: 0.009152935817837715\n",
            "eopch: 15 step: 16 loss: 0.007521079387515783\n",
            "eopch: 16 step: 1 loss: 0.009857423603534698\n",
            "eopch: 16 step: 2 loss: 0.011708034202456474\n",
            "eopch: 16 step: 3 loss: 0.007725825067609549\n",
            "eopch: 16 step: 4 loss: 0.004217212088406086\n",
            "eopch: 16 step: 5 loss: 0.005202772095799446\n",
            "eopch: 16 step: 6 loss: 0.005162328016012907\n",
            "eopch: 16 step: 7 loss: 0.007173385936766863\n",
            "eopch: 16 step: 8 loss: 0.008078854531049728\n",
            "eopch: 16 step: 9 loss: 0.00876722950488329\n",
            "eopch: 16 step: 10 loss: 0.009216779842972755\n",
            "eopch: 16 step: 11 loss: 0.0076225632801651955\n",
            "eopch: 16 step: 12 loss: 0.007493014447391033\n",
            "eopch: 16 step: 13 loss: 0.006840638816356659\n",
            "eopch: 16 step: 14 loss: 0.006260943599045277\n",
            "eopch: 16 step: 15 loss: 0.006267854943871498\n",
            "eopch: 16 step: 16 loss: 0.0036250133998692036\n",
            "eopch: 17 step: 1 loss: 0.006062418222427368\n",
            "eopch: 17 step: 2 loss: 0.008045505732297897\n",
            "eopch: 17 step: 3 loss: 0.01121734082698822\n",
            "eopch: 17 step: 4 loss: 0.010267757810652256\n",
            "eopch: 17 step: 5 loss: 0.008434937335550785\n",
            "eopch: 17 step: 6 loss: 0.006017225794494152\n",
            "eopch: 17 step: 7 loss: 0.0036982125602662563\n",
            "eopch: 17 step: 8 loss: 0.003566551487892866\n",
            "eopch: 17 step: 9 loss: 0.003926418721675873\n",
            "eopch: 17 step: 10 loss: 0.0057592084631323814\n",
            "eopch: 17 step: 11 loss: 0.008617045357823372\n",
            "eopch: 17 step: 12 loss: 0.006496571470052004\n",
            "eopch: 17 step: 13 loss: 0.008654293604195118\n",
            "eopch: 17 step: 14 loss: 0.004185333847999573\n",
            "eopch: 17 step: 15 loss: 0.004834027495235205\n",
            "eopch: 17 step: 16 loss: 0.003763950662687421\n",
            "eopch: 18 step: 1 loss: 0.006033528596162796\n",
            "eopch: 18 step: 2 loss: 0.006129013374447823\n",
            "eopch: 18 step: 3 loss: 0.004124735947698355\n",
            "eopch: 18 step: 4 loss: 0.004135599825531244\n",
            "eopch: 18 step: 5 loss: 0.004978007636964321\n",
            "eopch: 18 step: 6 loss: 0.005523649975657463\n",
            "eopch: 18 step: 7 loss: 0.003731000702828169\n",
            "eopch: 18 step: 8 loss: 0.004413061775267124\n",
            "eopch: 18 step: 9 loss: 0.004576290957629681\n",
            "eopch: 18 step: 10 loss: 0.0029216003604233265\n",
            "eopch: 18 step: 11 loss: 0.005794729106128216\n",
            "eopch: 18 step: 12 loss: 0.0031210235320031643\n",
            "eopch: 18 step: 13 loss: 0.003116060746833682\n",
            "eopch: 18 step: 14 loss: 0.0022818513680249453\n",
            "eopch: 18 step: 15 loss: 0.002533742692321539\n",
            "eopch: 18 step: 16 loss: 0.0018877554684877396\n",
            "eopch: 19 step: 1 loss: 0.005867325700819492\n",
            "eopch: 19 step: 2 loss: 0.0017663977341726422\n",
            "eopch: 19 step: 3 loss: 0.00160981435328722\n",
            "eopch: 19 step: 4 loss: 0.0020062350668013096\n",
            "eopch: 19 step: 5 loss: 0.0012188733089715242\n",
            "eopch: 19 step: 6 loss: 0.0014174147509038448\n",
            "eopch: 19 step: 7 loss: 0.0014024008996784687\n",
            "eopch: 19 step: 8 loss: 0.001948663149960339\n",
            "eopch: 19 step: 9 loss: 0.0016868349630385637\n",
            "eopch: 19 step: 10 loss: 0.003078544745221734\n",
            "eopch: 19 step: 11 loss: 0.0019184753764420748\n",
            "eopch: 19 step: 12 loss: 0.001644930220209062\n",
            "eopch: 19 step: 13 loss: 0.0015794236678630114\n",
            "eopch: 19 step: 14 loss: 0.0010507479310035706\n",
            "eopch: 19 step: 15 loss: 0.001816984498873353\n",
            "eopch: 19 step: 16 loss: 0.000729477615095675\n",
            "eopch: 20 step: 1 loss: 0.0010689180344343185\n",
            "eopch: 20 step: 2 loss: 0.0021112733520567417\n",
            "eopch: 20 step: 3 loss: 0.0008819198119454086\n",
            "eopch: 20 step: 4 loss: 0.001035523135215044\n",
            "eopch: 20 step: 5 loss: 0.0018744261469691992\n",
            "eopch: 20 step: 6 loss: 0.0009387501631863415\n",
            "eopch: 20 step: 7 loss: 0.0012888461351394653\n",
            "eopch: 20 step: 8 loss: 0.0009836711687967181\n",
            "eopch: 20 step: 9 loss: 0.0015820221742615104\n",
            "eopch: 20 step: 10 loss: 0.0007103446405380964\n",
            "eopch: 20 step: 11 loss: 0.002369774505496025\n",
            "eopch: 20 step: 12 loss: 0.0014166035689413548\n",
            "eopch: 20 step: 13 loss: 0.0023663288448005915\n",
            "eopch: 20 step: 14 loss: 0.0020543283317238092\n",
            "eopch: 20 step: 15 loss: 0.0019031963311135769\n",
            "eopch: 20 step: 16 loss: 0.0006133010028861463\n",
            "eopch: 21 step: 1 loss: 0.0011921899858862162\n",
            "eopch: 21 step: 2 loss: 0.000658057106193155\n",
            "eopch: 21 step: 3 loss: 0.0009218776249326766\n",
            "eopch: 21 step: 4 loss: 0.001586390077136457\n",
            "eopch: 21 step: 5 loss: 0.0005218200967647135\n",
            "eopch: 21 step: 6 loss: 0.0016118775820359588\n",
            "eopch: 21 step: 7 loss: 0.0013151594903320074\n",
            "eopch: 21 step: 8 loss: 0.000864074332639575\n",
            "eopch: 21 step: 9 loss: 0.0006431777728721499\n",
            "eopch: 21 step: 10 loss: 0.0012202623765915632\n",
            "eopch: 21 step: 11 loss: 0.0003238369827158749\n",
            "eopch: 21 step: 12 loss: 0.0003379365080036223\n",
            "eopch: 21 step: 13 loss: 0.0007245347951538861\n",
            "eopch: 21 step: 14 loss: 0.003014670219272375\n",
            "eopch: 21 step: 15 loss: 0.0017505820142105222\n",
            "eopch: 21 step: 16 loss: 0.0012105786008760333\n",
            "eopch: 22 step: 1 loss: 0.0004641096165869385\n",
            "eopch: 22 step: 2 loss: 0.0011624230537563562\n",
            "eopch: 22 step: 3 loss: 0.0018171692499890924\n",
            "eopch: 22 step: 4 loss: 0.0006336889346130192\n",
            "eopch: 22 step: 5 loss: 0.00017628615023568273\n",
            "eopch: 22 step: 6 loss: 0.0013832058757543564\n",
            "eopch: 22 step: 7 loss: 0.0022297888062894344\n",
            "eopch: 22 step: 8 loss: 0.0007811932009644806\n",
            "eopch: 22 step: 9 loss: 0.0012278244830667973\n",
            "eopch: 22 step: 10 loss: 0.00033550639636814594\n",
            "eopch: 22 step: 11 loss: 0.0005497505189850926\n",
            "eopch: 22 step: 12 loss: 0.0005608377396129072\n",
            "eopch: 22 step: 13 loss: 0.0003487151116132736\n",
            "eopch: 22 step: 14 loss: 0.00015430971689056605\n",
            "eopch: 22 step: 15 loss: 0.002416772535070777\n",
            "eopch: 22 step: 16 loss: 0.0006278051878325641\n",
            "eopch: 23 step: 1 loss: 0.0008659386076033115\n",
            "eopch: 23 step: 2 loss: 0.0024800198152661324\n",
            "eopch: 23 step: 3 loss: 0.0003238844219595194\n",
            "eopch: 23 step: 4 loss: 0.0006749511230736971\n",
            "eopch: 23 step: 5 loss: 0.00021359084348659962\n",
            "eopch: 23 step: 6 loss: 0.0008366129477508366\n",
            "eopch: 23 step: 7 loss: 0.0011023913975805044\n",
            "eopch: 23 step: 8 loss: 0.0005367574049159884\n",
            "eopch: 23 step: 9 loss: 0.0005112733924761415\n",
            "eopch: 23 step: 10 loss: 0.002508555306121707\n",
            "eopch: 23 step: 11 loss: 0.0011071821209043264\n",
            "eopch: 23 step: 12 loss: 0.001612204359844327\n",
            "eopch: 23 step: 13 loss: 0.00021682382794097066\n",
            "eopch: 23 step: 14 loss: 0.00024039704294409603\n",
            "eopch: 23 step: 15 loss: 0.00032909330911934376\n",
            "eopch: 23 step: 16 loss: 0.0001339337759418413\n",
            "eopch: 24 step: 1 loss: 0.0004181104595772922\n",
            "eopch: 24 step: 2 loss: 0.0010656516533344984\n",
            "eopch: 24 step: 3 loss: 0.0030168902594596148\n",
            "eopch: 24 step: 4 loss: 0.00032389446278102696\n",
            "eopch: 24 step: 5 loss: 0.0001792108960216865\n",
            "eopch: 24 step: 6 loss: 0.00038734590634703636\n",
            "eopch: 24 step: 7 loss: 0.0007821733015589416\n",
            "eopch: 24 step: 8 loss: 0.00022373591491486877\n",
            "eopch: 24 step: 9 loss: 0.0029518469236791134\n",
            "eopch: 24 step: 10 loss: 0.0002844692498911172\n",
            "eopch: 24 step: 11 loss: 0.0002932173083536327\n",
            "eopch: 24 step: 12 loss: 0.0001842709316406399\n",
            "eopch: 24 step: 13 loss: 0.0001521009544376284\n",
            "eopch: 24 step: 14 loss: 0.00032673488021828234\n",
            "eopch: 24 step: 15 loss: 0.0006851516081951559\n",
            "eopch: 24 step: 16 loss: 0.0002559660351835191\n",
            "eopch: 25 step: 1 loss: 0.0010633363854140043\n",
            "eopch: 25 step: 2 loss: 0.0009131677797995508\n",
            "eopch: 25 step: 3 loss: 8.07462347438559e-05\n",
            "eopch: 25 step: 4 loss: 0.001107500633224845\n",
            "eopch: 25 step: 5 loss: 0.0020192041993141174\n",
            "eopch: 25 step: 6 loss: 0.00010276339889969677\n",
            "eopch: 25 step: 7 loss: 0.00010024957009591162\n",
            "eopch: 25 step: 8 loss: 0.00012230165884830058\n",
            "eopch: 25 step: 9 loss: 5.739229527534917e-05\n",
            "eopch: 25 step: 10 loss: 0.0001326839264947921\n",
            "eopch: 25 step: 11 loss: 0.00025928494869731367\n",
            "eopch: 25 step: 12 loss: 0.0001819456520024687\n",
            "eopch: 25 step: 13 loss: 0.00010135972843272611\n",
            "eopch: 25 step: 14 loss: 0.00015112718392629176\n",
            "eopch: 25 step: 15 loss: 0.00042736451723612845\n",
            "eopch: 25 step: 16 loss: 0.00013069027045276016\n",
            "eopch: 26 step: 1 loss: 4.9051370297092944e-05\n",
            "eopch: 26 step: 2 loss: 7.64319920563139e-05\n",
            "eopch: 26 step: 3 loss: 4.761034870170988e-05\n",
            "eopch: 26 step: 4 loss: 2.5407116481801495e-05\n",
            "eopch: 26 step: 5 loss: 1.6420810425188392e-05\n",
            "eopch: 26 step: 6 loss: 2.2320897187455557e-05\n",
            "eopch: 26 step: 7 loss: 0.0001856897579273209\n",
            "eopch: 26 step: 8 loss: 0.0005159300053492188\n",
            "eopch: 26 step: 9 loss: 0.0004820913600269705\n",
            "eopch: 26 step: 10 loss: 0.00014629613724537194\n",
            "eopch: 26 step: 11 loss: 1.415730730514042e-05\n",
            "eopch: 26 step: 12 loss: 3.139031832688488e-05\n",
            "eopch: 26 step: 13 loss: 2.5629242372815497e-05\n",
            "eopch: 26 step: 14 loss: 2.324520391994156e-05\n",
            "eopch: 26 step: 15 loss: 1.827871528803371e-05\n",
            "eopch: 26 step: 16 loss: 7.903828191047069e-06\n",
            "eopch: 27 step: 1 loss: 2.249027784273494e-05\n",
            "eopch: 27 step: 2 loss: 3.9127837226260453e-05\n",
            "eopch: 27 step: 3 loss: 2.1560566892731003e-05\n",
            "eopch: 27 step: 4 loss: 2.1474763343576342e-05\n",
            "eopch: 27 step: 5 loss: 1.146113845607033e-05\n",
            "eopch: 27 step: 6 loss: 1.452770084142685e-05\n",
            "eopch: 27 step: 7 loss: 0.00016711480566300452\n",
            "eopch: 27 step: 8 loss: 1.1939036994590424e-05\n",
            "eopch: 27 step: 9 loss: 2.0255110939615406e-05\n",
            "eopch: 27 step: 10 loss: 0.00020042757387273014\n",
            "eopch: 27 step: 11 loss: 8.826479643175844e-06\n",
            "eopch: 27 step: 12 loss: 1.0438516255817376e-05\n",
            "eopch: 27 step: 13 loss: 1.3735027096117847e-05\n",
            "eopch: 27 step: 14 loss: 1.3805293747282121e-05\n",
            "eopch: 27 step: 15 loss: 1.2441205399227329e-05\n",
            "eopch: 27 step: 16 loss: 3.4208580927952426e-06\n",
            "eopch: 28 step: 1 loss: 9.557461453368887e-06\n",
            "eopch: 28 step: 2 loss: 8.614629223302472e-06\n",
            "eopch: 28 step: 3 loss: 9.681907613412477e-06\n",
            "eopch: 28 step: 4 loss: 7.738736167084426e-05\n",
            "eopch: 28 step: 5 loss: 6.169642801978625e-06\n",
            "eopch: 28 step: 6 loss: 4.24310564994812e-05\n",
            "eopch: 28 step: 7 loss: 1.6766018234193325e-05\n",
            "eopch: 28 step: 8 loss: 9.90977969195228e-06\n",
            "eopch: 28 step: 9 loss: 0.00014350772835314274\n",
            "eopch: 28 step: 10 loss: 8.009335033420939e-06\n",
            "eopch: 28 step: 11 loss: 8.209803127101623e-06\n",
            "eopch: 28 step: 12 loss: 7.4672534537967294e-06\n",
            "eopch: 28 step: 13 loss: 9.179469998343848e-06\n",
            "eopch: 28 step: 14 loss: 8.720908226678148e-06\n",
            "eopch: 28 step: 15 loss: 7.807066140230745e-06\n",
            "eopch: 28 step: 16 loss: 2.251864543723059e-06\n",
            "eopch: 29 step: 1 loss: 6.9968523348507006e-06\n",
            "eopch: 29 step: 2 loss: 6.504534212581348e-06\n",
            "eopch: 29 step: 3 loss: 1.4271070540416986e-05\n",
            "eopch: 29 step: 4 loss: 5.949085789325181e-06\n",
            "eopch: 29 step: 5 loss: 4.309577889216598e-06\n",
            "eopch: 29 step: 6 loss: 5.939343736827141e-06\n",
            "eopch: 29 step: 7 loss: 6.935809324204456e-06\n",
            "eopch: 29 step: 8 loss: 5.751525350206066e-06\n",
            "eopch: 29 step: 9 loss: 6.673190000583418e-06\n",
            "eopch: 29 step: 10 loss: 5.553412847802974e-06\n",
            "eopch: 29 step: 11 loss: 5.708944627258461e-06\n",
            "eopch: 29 step: 12 loss: 6.888173174957046e-06\n",
            "eopch: 29 step: 13 loss: 7.845610525691882e-06\n",
            "eopch: 29 step: 14 loss: 1.2323853297857568e-05\n",
            "eopch: 29 step: 15 loss: 6.7245027821627446e-06\n",
            "eopch: 29 step: 16 loss: 1.8921040236818953e-06\n",
            "eopch: 30 step: 1 loss: 8.353590601473115e-06\n",
            "eopch: 30 step: 2 loss: 5.96021163801197e-06\n",
            "eopch: 30 step: 3 loss: 9.827283975027967e-06\n",
            "eopch: 30 step: 4 loss: 5.9320227592252195e-06\n",
            "eopch: 30 step: 5 loss: 3.4066097214235924e-06\n",
            "eopch: 30 step: 6 loss: 4.461789103515912e-06\n",
            "eopch: 30 step: 7 loss: 5.815033091494115e-06\n",
            "eopch: 30 step: 8 loss: 4.454525424080202e-06\n",
            "eopch: 30 step: 9 loss: 4.714900569524616e-06\n",
            "eopch: 30 step: 10 loss: 4.013794296042761e-06\n",
            "eopch: 30 step: 11 loss: 3.8014450183254667e-06\n",
            "eopch: 30 step: 12 loss: 5.056933332525659e-06\n",
            "eopch: 30 step: 13 loss: 5.5499472182418685e-06\n",
            "eopch: 30 step: 14 loss: 5.473724286275683e-06\n",
            "eopch: 30 step: 15 loss: 4.680875463236589e-06\n",
            "eopch: 30 step: 16 loss: 1.4633716318712686e-06\n",
            "eopch: 31 step: 1 loss: 4.6930417738622054e-06\n",
            "eopch: 31 step: 2 loss: 3.672799039122765e-06\n",
            "eopch: 31 step: 3 loss: 3.7322706702980213e-06\n",
            "eopch: 31 step: 4 loss: 3.738275609066477e-06\n",
            "eopch: 31 step: 5 loss: 2.5827403078437783e-06\n",
            "eopch: 31 step: 6 loss: 3.4628030789463082e-06\n",
            "eopch: 31 step: 7 loss: 3.7912702737230575e-06\n",
            "eopch: 31 step: 8 loss: 3.4571171454444993e-06\n",
            "eopch: 31 step: 9 loss: 3.6640717553382274e-06\n",
            "eopch: 31 step: 10 loss: 3.120691417279886e-06\n",
            "eopch: 31 step: 11 loss: 2.788333858916303e-06\n",
            "eopch: 31 step: 12 loss: 3.917205503967125e-06\n",
            "eopch: 31 step: 13 loss: 4.366392204246949e-06\n",
            "eopch: 31 step: 14 loss: 4.326133876020322e-06\n",
            "eopch: 31 step: 15 loss: 3.666479642561171e-06\n",
            "eopch: 31 step: 16 loss: 1.216136524817557e-06\n",
            "eopch: 32 step: 1 loss: 3.7403165151772555e-06\n",
            "eopch: 32 step: 2 loss: 2.932468078142847e-06\n",
            "eopch: 32 step: 3 loss: 2.9596039894386195e-06\n",
            "eopch: 32 step: 4 loss: 2.9899977107561426e-06\n",
            "eopch: 32 step: 5 loss: 2.1427922547445633e-06\n",
            "eopch: 32 step: 6 loss: 2.896254500228679e-06\n",
            "eopch: 32 step: 7 loss: 3.067720626859227e-06\n",
            "eopch: 32 step: 8 loss: 2.9145567168598063e-06\n",
            "eopch: 32 step: 9 loss: 3.066510998905869e-06\n",
            "eopch: 32 step: 10 loss: 2.632780706335325e-06\n",
            "eopch: 32 step: 11 loss: 2.3007969502941705e-06\n",
            "eopch: 32 step: 12 loss: 3.2528075735172024e-06\n",
            "eopch: 32 step: 13 loss: 3.6698270378110465e-06\n",
            "eopch: 32 step: 14 loss: 3.636821020336356e-06\n",
            "eopch: 32 step: 15 loss: 3.084207946812967e-06\n",
            "eopch: 32 step: 16 loss: 1.0505115142223076e-06\n",
            "eopch: 33 step: 1 loss: 3.1960212254489306e-06\n",
            "eopch: 33 step: 2 loss: 2.4938017304521054e-06\n",
            "eopch: 33 step: 3 loss: 2.5297829324699705e-06\n",
            "eopch: 33 step: 4 loss: 2.545239112805575e-06\n",
            "eopch: 33 step: 5 loss: 1.8528539840190206e-06\n",
            "eopch: 33 step: 6 loss: 2.509439582354389e-06\n",
            "eopch: 33 step: 7 loss: 2.6303819140593987e-06\n",
            "eopch: 33 step: 8 loss: 2.5412334707652917e-06\n",
            "eopch: 33 step: 9 loss: 2.6593529582896736e-06\n",
            "eopch: 33 step: 10 loss: 2.295086687809089e-06\n",
            "eopch: 33 step: 11 loss: 1.983197307708906e-06\n",
            "eopch: 33 step: 12 loss: 2.8052729703631485e-06\n",
            "eopch: 33 step: 13 loss: 3.1788456453796243e-06\n",
            "eopch: 33 step: 14 loss: 3.1535064408672042e-06\n",
            "eopch: 33 step: 15 loss: 2.6879120014200453e-06\n",
            "eopch: 33 step: 16 loss: 9.262148523703218e-07\n",
            "eopch: 34 step: 1 loss: 2.8063282115908805e-06\n",
            "eopch: 34 step: 2 loss: 2.181879381168983e-06\n",
            "eopch: 34 step: 3 loss: 2.224607897005626e-06\n",
            "eopch: 34 step: 4 loss: 2.2266256110015092e-06\n",
            "eopch: 34 step: 5 loss: 1.637123091313697e-06\n",
            "eopch: 34 step: 6 loss: 2.217051587649621e-06\n",
            "eopch: 34 step: 7 loss: 2.3150657852966106e-06\n",
            "eopch: 34 step: 8 loss: 2.257251026094309e-06\n",
            "eopch: 34 step: 9 loss: 2.3532645627710735e-06\n",
            "eopch: 34 step: 10 loss: 2.038595084741246e-06\n",
            "eopch: 34 step: 11 loss: 1.7489428500994109e-06\n",
            "eopch: 34 step: 12 loss: 2.473359927535057e-06\n",
            "eopch: 34 step: 13 loss: 2.803658844641177e-06\n",
            "eopch: 34 step: 14 loss: 2.7872833925357554e-06\n",
            "eopch: 34 step: 15 loss: 2.3907118702481966e-06\n",
            "eopch: 34 step: 16 loss: 8.277059464489867e-07\n",
            "eopch: 35 step: 1 loss: 2.5049346277228324e-06\n",
            "eopch: 35 step: 2 loss: 1.941537448146846e-06\n",
            "eopch: 35 step: 3 loss: 1.988276380870957e-06\n",
            "eopch: 35 step: 4 loss: 1.9804724615823943e-06\n",
            "eopch: 35 step: 5 loss: 1.4667061805084813e-06\n",
            "eopch: 35 step: 6 loss: 1.984553591682925e-06\n",
            "eopch: 35 step: 7 loss: 2.069738684440381e-06\n",
            "eopch: 35 step: 8 loss: 2.0296683942433447e-06\n",
            "eopch: 35 step: 9 loss: 2.1106950498506194e-06\n",
            "eopch: 35 step: 10 loss: 1.8337242408961174e-06\n",
            "eopch: 35 step: 11 loss: 1.565244701851043e-06\n",
            "eopch: 35 step: 12 loss: 2.2130807337816805e-06\n",
            "eopch: 35 step: 13 loss: 2.5047140752576524e-06\n",
            "eopch: 35 step: 14 loss: 2.4964610929600894e-06\n",
            "eopch: 35 step: 15 loss: 2.1547602955251932e-06\n",
            "eopch: 35 step: 16 loss: 7.465930025318812e-07\n",
            "eopch: 36 step: 1 loss: 2.261037479911465e-06\n",
            "eopch: 36 step: 2 loss: 1.7488678167865146e-06\n",
            "eopch: 36 step: 3 loss: 1.7971671013583546e-06\n",
            "eopch: 36 step: 4 loss: 1.7821660094341496e-06\n",
            "eopch: 36 step: 5 loss: 1.3278176993480884e-06\n",
            "eopch: 36 step: 6 loss: 1.7936208678293042e-06\n",
            "eopch: 36 step: 7 loss: 1.8706815581026603e-06\n",
            "eopch: 36 step: 8 loss: 1.842687538555765e-06\n",
            "eopch: 36 step: 9 loss: 1.9119556782243308e-06\n",
            "eopch: 36 step: 10 loss: 1.6649621557007777e-06\n",
            "eopch: 36 step: 11 loss: 1.41601185532636e-06\n",
            "eopch: 36 step: 12 loss: 2.0014722394989803e-06\n",
            "eopch: 36 step: 13 loss: 2.260389010189101e-06\n",
            "eopch: 36 step: 14 loss: 2.2583931240660604e-06\n",
            "eopch: 36 step: 15 loss: 1.961065436262288e-06\n",
            "eopch: 36 step: 16 loss: 6.786557946725225e-07\n",
            "eopch: 37 step: 1 loss: 2.0591119209711906e-06\n",
            "eopch: 37 step: 2 loss: 1.5894638636382297e-06\n",
            "eopch: 37 step: 3 loss: 1.6384451555495616e-06\n",
            "eopch: 37 step: 4 loss: 1.618804731151613e-06\n",
            "eopch: 37 step: 5 loss: 1.2115933714085259e-06\n",
            "eopch: 37 step: 6 loss: 1.6342648905265378e-06\n",
            "eopch: 37 step: 7 loss: 1.7053931742339046e-06\n",
            "eopch: 37 step: 8 loss: 1.6852955013746396e-06\n",
            "eopch: 37 step: 9 loss: 1.7457797412134823e-06\n",
            "eopch: 37 step: 10 loss: 1.5232080841087736e-06\n",
            "eopch: 37 step: 11 loss: 1.291770445277507e-06\n",
            "eopch: 37 step: 12 loss: 1.8253193729833583e-06\n",
            "eopch: 37 step: 13 loss: 2.0565857994370162e-06\n",
            "eopch: 37 step: 14 loss: 2.0595678051904542e-06\n",
            "eopch: 37 step: 15 loss: 1.7981290056923172e-06\n",
            "eopch: 37 step: 16 loss: 6.2109705822877e-07\n",
            "eopch: 38 step: 1 loss: 1.8882402628150885e-06\n",
            "eopch: 38 step: 2 loss: 1.4553307892128942e-06\n",
            "eopch: 38 step: 3 loss: 1.5039913705550134e-06\n",
            "eopch: 38 step: 4 loss: 1.4813099369348492e-06\n",
            "eopch: 38 step: 5 loss: 1.1129343420179794e-06\n",
            "eopch: 38 step: 6 loss: 1.49846982822055e-06\n",
            "eopch: 38 step: 7 loss: 1.5653521359126898e-06\n",
            "eopch: 38 step: 8 loss: 1.5509783679590328e-06\n",
            "eopch: 38 step: 9 loss: 1.6039787169574993e-06\n",
            "eopch: 38 step: 10 loss: 1.401687086399761e-06\n",
            "eopch: 38 step: 11 loss: 1.1862007340823766e-06\n",
            "eopch: 38 step: 12 loss: 1.6761728147685062e-06\n",
            "eopch: 38 step: 13 loss: 1.8833072772395099e-06\n",
            "eopch: 38 step: 14 loss: 1.8906083596448298e-06\n",
            "eopch: 38 step: 15 loss: 1.6592088059041998e-06\n",
            "eopch: 38 step: 16 loss: 5.71715588648658e-07\n",
            "eopch: 39 step: 1 loss: 1.7416821265214821e-06\n",
            "eopch: 39 step: 2 loss: 1.3405939398580813e-06\n",
            "eopch: 39 step: 3 loss: 1.3883336578146555e-06\n",
            "eopch: 39 step: 4 loss: 1.3637463780469261e-06\n",
            "eopch: 39 step: 5 loss: 1.0278480431225034e-06\n",
            "eopch: 39 step: 6 loss: 1.3816447790304665e-06\n",
            "eopch: 39 step: 7 loss: 1.4451190963882254e-06\n",
            "eopch: 39 step: 8 loss: 1.4348029253596906e-06\n",
            "eopch: 39 step: 9 loss: 1.4819319176240242e-06\n",
            "eopch: 39 step: 10 loss: 1.2971935348105035e-06\n",
            "eopch: 39 step: 11 loss: 1.0959105338770314e-06\n",
            "eopch: 39 step: 12 loss: 1.5478171917493455e-06\n",
            "eopch: 39 step: 13 loss: 1.7344445950584486e-06\n",
            "eopch: 39 step: 14 loss: 1.74517708728672e-06\n",
            "eopch: 39 step: 15 loss: 1.5384406424345798e-06\n",
            "eopch: 39 step: 16 loss: 5.284420581119775e-07\n",
            "eopch: 40 step: 1 loss: 1.6142465710800025e-06\n",
            "eopch: 40 step: 2 loss: 1.2413020158419386e-06\n",
            "eopch: 40 step: 3 loss: 1.2876763548774761e-06\n",
            "eopch: 40 step: 4 loss: 1.2621844689419959e-06\n",
            "eopch: 40 step: 5 loss: 9.534791729493008e-07\n",
            "eopch: 40 step: 6 loss: 1.2796314194929437e-06\n",
            "eopch: 40 step: 7 loss: 1.3406706784735434e-06\n",
            "eopch: 40 step: 8 loss: 1.3333153674466303e-06\n",
            "eopch: 40 step: 9 loss: 1.375316287521855e-06\n",
            "eopch: 40 step: 10 loss: 1.20575509754417e-06\n",
            "eopch: 40 step: 11 loss: 1.0174240969718085e-06\n",
            "eopch: 40 step: 12 loss: 1.4359191027324414e-06\n",
            "eopch: 40 step: 13 loss: 1.6053761555667734e-06\n",
            "eopch: 40 step: 14 loss: 1.618341229914222e-06\n",
            "eopch: 40 step: 15 loss: 1.4329193618323188e-06\n",
            "eopch: 40 step: 16 loss: 4.906145818495133e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFjv5qTM3iqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "897ad730-ca58-481a-fc34-f9ab16a80f52"
      },
      "source": [
        "mod=torch.load('/content/captcharesnet_0.0000.pth')\n",
        "mod.eval();\n",
        "for step, (img, label_oh, label) in enumerate(test_dl):\n",
        "    img = Variable(img).cuda()\n",
        "    pred = mod(img)\n",
        "    c0 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[0:ALL_CHAR_SET_LEN])]\n",
        "    c1 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2])]\n",
        "    c2 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN*2:ALL_CHAR_SET_LEN*3])]\n",
        "    c3 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN*3:ALL_CHAR_SET_LEN*4])]\n",
        "    c4 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN*4:ALL_CHAR_SET_LEN*5])]\n",
        "    c = '%s%s%s%s%s' % (c0, c1, c2, c3, c4)\n",
        "\n",
        "    print('label:', label[0], 'pred:', c)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label: n4wwn pred: n4wwn\n",
            "label: m5meg pred: m5meg\n",
            "label: de7f8 pred: de7f8\n",
            "label: f228n pred: f228n\n",
            "label: dw6mn pred: dw6mn\n",
            "label: 44ype pred: 44ype\n",
            "label: emwpn pred: emwpn\n",
            "label: y4n6m pred: y4n6m\n",
            "label: w6yne pred: w6yne\n",
            "label: d2n8x pred: d2n8x\n",
            "label: 5np4m pred: 5np4m\n",
            "label: nm248 pred: nm248\n",
            "label: fp382 pred: fp382\n",
            "label: bxxfc pred: bxxfc\n",
            "label: 7e2y7 pred: 7e2y7\n",
            "label: n4b4m pred: n4b4m\n",
            "label: 3ygde pred: 3ygde\n",
            "label: pn7pn pred: pn7pn\n",
            "label: p7fyp pred: p7fyp\n",
            "label: gcx6f pred: gcx6f\n",
            "label: nfcb5 pred: nfcb5\n",
            "label: 5mfff pred: 5mfff\n",
            "label: x6pdb pred: x6pdb\n",
            "label: 8bbw8 pred: 8bbw8\n",
            "label: m75bf pred: m75bf\n",
            "label: 57gnx pred: 57gnx\n",
            "label: 2nx38 pred: 2nx38\n",
            "label: x6b5m pred: x6b5m\n",
            "label: x74b2 pred: x74b2\n",
            "label: 87d4c pred: 87d4c\n",
            "label: f6ne5 pred: f6ne5\n",
            "label: c2fb7 pred: c2fb7\n",
            "label: 5n728 pred: 5n728\n",
            "label: bn5mw pred: bn5mw\n",
            "label: 2356g pred: 2356g\n",
            "label: nnn5p pred: nnn5p\n",
            "label: mbp2y pred: mbp2y\n",
            "label: 5nxnn pred: 5nxnn\n",
            "label: pmd3w pred: pmd3w\n",
            "label: 8w875 pred: 8w875\n",
            "label: 42dw4 pred: 42dw4\n",
            "label: 2yggg pred: 2yggg\n",
            "label: 37d52 pred: 37d52\n",
            "label: wg625 pred: wg625\n",
            "label: men4f pred: men4f\n",
            "label: nxx25 pred: nxx25\n",
            "label: pg2pm pred: pg2pm\n",
            "label: 6m5eg pred: 6m5eg\n",
            "label: 8db67 pred: 8db67\n",
            "label: 573d8 pred: 573d8\n",
            "label: wbncw pred: wbncw\n",
            "label: mmy5n pred: mmy5n\n",
            "label: dmx8p pred: dmx8p\n",
            "label: enn7n pred: enn7n\n",
            "label: en4n4 pred: en4n4\n",
            "label: nfndw pred: nfndw\n",
            "label: 4gb3f pred: 4gb3f\n",
            "label: e3ndn pred: e3ndn\n",
            "label: 3den6 pred: 3den6\n",
            "label: 8np22 pred: 8np22\n",
            "label: cffp4 pred: cffp4\n",
            "label: bw44w pred: bw44w\n",
            "label: dbny3 pred: dbny3\n",
            "label: geyn5 pred: geyn5\n",
            "label: byfgn pred: byfgn\n",
            "label: 52447 pred: 52447\n",
            "label: 34b84 pred: 34b84\n",
            "label: d66cn pred: d66cn\n",
            "label: fcey3 pred: fcey3\n",
            "label: efb3f pred: efb3f\n",
            "label: xmcym pred: xmcym\n",
            "label: mwdf6 pred: mwdf6\n",
            "label: xfn6n pred: xfn6n\n",
            "label: 8gmnx pred: 8gmnx\n",
            "label: 5ywwf pred: 5ywwf\n",
            "label: 6bdn5 pred: 6bdn5\n",
            "label: 8b735 pred: 8b735\n",
            "label: 3n3cf pred: 3n3cf\n",
            "label: xf5g7 pred: xf5g7\n",
            "label: by5y3 pred: by5y3\n",
            "label: 5325m pred: 5325m\n",
            "label: 8fexn pred: 8fexn\n",
            "label: 6bnnm pred: 6bnnm\n",
            "label: nn4wx pred: nn4wx\n",
            "label: 7fde7 pred: 7fde7\n",
            "label: y5g87 pred: y5g87\n",
            "label: 6n6gg pred: 6n6gg\n",
            "label: ygenn pred: ygenn\n",
            "label: pybee pred: pybee\n",
            "label: n7ff2 pred: n7ff2\n",
            "label: cfc2y pred: cfc2y\n",
            "label: cnex4 pred: cnex4\n",
            "label: yemy4 pred: yemy4\n",
            "label: m4fd8 pred: m4fd8\n",
            "label: 36bc2 pred: 36bc2\n",
            "label: 2nf26 pred: 2nf26\n",
            "label: wnmyn pred: wnmyn\n",
            "label: wm746 pred: wm746\n",
            "label: 6wnyc pred: 6wnyc\n",
            "label: y2ye8 pred: y2ye8\n",
            "label: gy5bf pred: gy5bf\n",
            "label: gcfgp pred: gcfgp\n",
            "label: p6mn8 pred: p6mn8\n",
            "label: 64b3p pred: 64b3p\n",
            "label: w2yp7 pred: w2yp7\n",
            "label: bw6n6 pred: bw6n6\n",
            "label: 6pfy4 pred: 6pfy4\n",
            "label: pxdwp pred: pxdwp\n",
            "label: c7gb3 pred: c7gb3\n",
            "label: bny4w pred: bny4w\n",
            "label: 5nggg pred: 5nggg\n",
            "label: yx2d4 pred: yx2d4\n",
            "label: pgmn2 pred: pgmn2\n",
            "label: xxw44 pred: xxw44\n",
            "label: cc845 pred: cc845\n",
            "label: be3bp pred: be3bp\n",
            "label: 3dgmf pred: 3dgmf\n",
            "label: yeyn4 pred: yeyn4\n",
            "label: ddnpf pred: ddnpf\n",
            "label: d2nbn pred: d2nbn\n",
            "label: 47m2b pred: 47m2b\n",
            "label: ndecc pred: ndecc\n",
            "label: ypw3d pred: ypw3d\n",
            "label: dw8d3 pred: dw8d3\n",
            "label: 6c3p5 pred: 6c3p5\n",
            "label: nc4yg pred: nc4yg\n",
            "label: 25p2m pred: 25p2m\n",
            "label: 8d8ep pred: 8d8ep\n",
            "label: fg7mg pred: fg7mg\n",
            "label: 6dmx7 pred: 6dmx7\n",
            "label: c3572 pred: c3572\n",
            "label: 5n3w4 pred: 5n3w4\n",
            "label: c8n8c pred: c8n8c\n",
            "label: b43nw pred: b43nw\n",
            "label: gpxng pred: gpxng\n",
            "label: pdw38 pred: pdw38\n",
            "label: fp3wy pred: fp3wy\n",
            "label: xdcn4 pred: xdcn4\n",
            "label: 28348 pred: 28348\n",
            "label: gn2d3 pred: gn2d3\n",
            "label: npxb7 pred: npxb7\n",
            "label: ny5dp pred: ny5dp\n",
            "label: 7gnge pred: 7gnge\n",
            "label: gegw4 pred: gegw4\n",
            "label: y7mnm pred: y7mnm\n",
            "label: nmw46 pred: nmw46\n",
            "label: enpw2 pred: enpw2\n",
            "label: pyf65 pred: pyf65\n",
            "label: 8y6b3 pred: 8y6b3\n",
            "label: gpnxn pred: gpnxn\n",
            "label: bd3b7 pred: bd3b7\n",
            "label: 62nb3 pred: 62nb3\n",
            "label: pg2yx pred: pg2yx\n",
            "label: bgb48 pred: bgb48\n",
            "label: cnwyc pred: cnwyc\n",
            "label: 3cpwb pred: 3cpwb\n",
            "label: c8fxy pred: c8fxy\n",
            "label: 5bb66 pred: 5bb66\n",
            "label: 7bwm2 pred: 7bwm2\n",
            "label: ddcne pred: ddcne\n",
            "label: c55c6 pred: c55c6\n",
            "label: mc35n pred: mc35n\n",
            "label: my84e pred: my84e\n",
            "label: n2c85 pred: n2c85\n",
            "label: dmw8n pred: dmw8n\n",
            "label: 556wd pred: 556wd\n",
            "label: nf2n8 pred: nf2n8\n",
            "label: 6e2dg pred: 6e2dg\n",
            "label: 4f8yp pred: 4f8yp\n",
            "label: ewcf5 pred: ewcf5\n",
            "label: gp22x pred: gp22x\n",
            "label: x5nyn pred: x5nyn\n",
            "label: g7wxw pred: g7wxw\n",
            "label: nf7bn pred: nf7bn\n",
            "label: 3nw7w pred: 3nw7w\n",
            "label: eppg3 pred: eppg3\n",
            "label: y5n6d pred: y5n6d\n",
            "label: nbcgb pred: nbcgb\n",
            "label: w2e87 pred: w2e87\n",
            "label: e7x45 pred: e7x45\n",
            "label: 46mbm pred: 46mbm\n",
            "label: ennmm pred: ennmm\n",
            "label: 6ge3p pred: 6ge3p\n",
            "label: 488de pred: 488de\n",
            "label: 244e2 pred: 244e2\n",
            "label: 4n2yg pred: 4n2yg\n",
            "label: 53mn8 pred: 53mn8\n",
            "label: d3c7y pred: d3c7y\n",
            "label: gfbx6 pred: gfbx6\n",
            "label: pf4nb pred: pf4nb\n",
            "label: n3xfg pred: n3xfg\n",
            "label: dd5w5 pred: dd5w5\n",
            "label: x347n pred: x347n\n",
            "label: 2xc2n pred: 2xc2n\n",
            "label: 33b22 pred: 33b22\n",
            "label: pcm7f pred: pcm7f\n",
            "label: bdg84 pred: bdg84\n",
            "label: 7gp47 pred: 7gp47\n",
            "label: 4fc36 pred: 4fc36\n",
            "label: m457d pred: m457d\n",
            "label: mnef5 pred: mnef5\n",
            "label: mn5c4 pred: mn5c4\n",
            "label: m67b3 pred: m67b3\n",
            "label: ygce8 pred: ygce8\n",
            "label: g3ex3 pred: g3ex3\n",
            "label: y2436 pred: y2436\n",
            "label: yew6p pred: yew6p\n",
            "label: pcede pred: pcede\n",
            "label: xfgxb pred: xfgxb\n",
            "label: 8d2nd pred: 8d2nd\n",
            "label: ebcbx pred: ebcbx\n",
            "label: yd755 pred: yd755\n",
            "label: m2576 pred: m2576\n",
            "label: c6745 pred: c6745\n",
            "label: 76nxn pred: 76nxn\n",
            "label: n3m6x pred: n3m6x\n",
            "label: n2by7 pred: n2by7\n",
            "label: 368y5 pred: 368y5\n",
            "label: 3p67n pred: 3p67n\n",
            "label: 7dxbd pred: 7dxbd\n",
            "label: e46yw pred: e46yw\n",
            "label: 3xng6 pred: 3xng6\n",
            "label: 6fg8c pred: 6fg8c\n",
            "label: yyn57 pred: yyn57\n",
            "label: edwny pred: edwny\n",
            "label: 4b2pw pred: 4b2pw\n",
            "label: feyc8 pred: feyc8\n",
            "label: dyp7n pred: dyp7n\n",
            "label: cpc8c pred: cpc8c\n",
            "label: 5bgp2 pred: 5bgp2\n",
            "label: 5bg8f pred: 5bg8f\n",
            "label: 8c23f pred: 8c23f\n",
            "label: 63pxe pred: 63pxe\n",
            "label: 4yc85 pred: 4yc85\n",
            "label: 4gycb pred: 4gycb\n",
            "label: ddmyg pred: ddmyg\n",
            "label: x8e8n pred: x8e8n\n",
            "label: 3x5fm pred: 3x5fm\n",
            "label: m6n4x pred: m6n4x\n",
            "label: 77wp4 pred: 77wp4\n",
            "label: b4ncn pred: b4ncn\n",
            "label: f22bn pred: f22bn\n",
            "label: 728n8 pred: 728n8\n",
            "label: 4dgf7 pred: 4dgf7\n",
            "label: y4g3b pred: y4g3b\n",
            "label: gnbn4 pred: gnbn4\n",
            "label: px2xp pred: px2xp\n",
            "label: 6c3n6 pred: 6c3n6\n",
            "label: 6ecbn pred: 6ecbn\n",
            "label: efgx5 pred: efgx5\n",
            "label: 25w53 pred: 25w53\n",
            "label: fg38b pred: fg38b\n",
            "label: 3b4we pred: 3b4we\n",
            "label: dyxnc pred: dyxnc\n",
            "label: 74eyg pred: 74eyg\n",
            "label: g2577 pred: g2577\n",
            "label: 6b4w6 pred: 6b4w6\n",
            "label: nxcmn pred: nxcmn\n",
            "label: m3b5p pred: m3b5p\n",
            "label: mcc2x pred: mcc2x\n",
            "label: defyx pred: defyx\n",
            "label: 474ff pred: 474ff\n",
            "label: n5wbg pred: n5wbg\n",
            "label: c2pg6 pred: c2pg6\n",
            "label: f753f pred: f753f\n",
            "label: mdyp7 pred: mdyp7\n",
            "label: 4nc37 pred: 4nc37\n",
            "label: 2w4y7 pred: 2w4y7\n",
            "label: fp5wn pred: fp5wn\n",
            "label: xp24p pred: xp24p\n",
            "label: 76n7p pred: 76n7p\n",
            "label: 2fxgd pred: 2fxgd\n",
            "label: n464c pred: n464c\n",
            "label: f6ww8 pred: f6ww8\n",
            "label: xnn4d pred: xnn4d\n",
            "label: xnnc3 pred: xnnc3\n",
            "label: fdpgd pred: fdpgd\n",
            "label: 55w5c pred: 55w5c\n",
            "label: ng6yp pred: ng6yp\n",
            "label: px8n8 pred: px8n8\n",
            "label: efg72 pred: efg72\n",
            "label: 3g2w6 pred: 3g2w6\n",
            "label: 43mn5 pred: 43mn5\n",
            "label: xemyg pred: xemyg\n",
            "label: x7547 pred: x7547\n",
            "label: 7d44m pred: 7d44m\n",
            "label: gm7n8 pred: gm7n8\n",
            "label: p2dw7 pred: p2dw7\n",
            "label: 5nnff pred: 5nnff\n",
            "label: pp87n pred: pp87n\n",
            "label: mg5nn pred: mg5nn\n",
            "label: 6n5fd pred: 6n5fd\n",
            "label: pe4xn pred: pe4xn\n",
            "label: en32e pred: en32e\n",
            "label: 3n2b4 pred: 3n2b4\n",
            "label: 4d22m pred: 4d22m\n",
            "label: 5g5e5 pred: 5g5e5\n",
            "label: 6f857 pred: 6f857\n",
            "label: 3fbxd pred: 3fbxd\n",
            "label: ymp7g pred: ymp7g\n",
            "label: gf2g4 pred: gf2g4\n",
            "label: p5nce pred: p5nce\n",
            "label: exycn pred: exycn\n",
            "label: 58b5m pred: 58b5m\n",
            "label: 2cgyx pred: 2cgyx\n",
            "label: p2x7x pred: p2x7x\n",
            "label: 7yf62 pred: 7yf62\n",
            "label: d22bd pred: d22bd\n",
            "label: 6bxwg pred: 6bxwg\n",
            "label: gxxpf pred: gxxpf\n",
            "label: f4wfn pred: f4wfn\n",
            "label: 3ndxd pred: 3ndxd\n",
            "label: pf5ng pred: pf5ng\n",
            "label: pmf5w pred: pmf5w\n",
            "label: 25egp pred: 25egp\n",
            "label: p24gn pred: p24gn\n",
            "label: mye68 pred: mye68\n",
            "label: 4fp5g pred: 4fp5g\n",
            "label: 3pe4g pred: 3pe4g\n",
            "label: b5fm7 pred: b5fm7\n",
            "label: 8ne4g pred: 8ne4g\n",
            "label: mp7wp pred: mp7wp\n",
            "label: cwgyx pred: cwgyx\n",
            "label: dw3nn pred: dw3nn\n",
            "label: ny3dw pred: ny3dw\n",
            "label: n8ydd pred: n8ydd\n",
            "label: xdn65 pred: xdn65\n",
            "label: w8f36 pred: w8f36\n",
            "label: 5p3mm pred: 5p3mm\n",
            "label: mpmy5 pred: mpmy5\n",
            "label: fc2ff pred: fc2ff\n",
            "label: n7meb pred: n7meb\n",
            "label: bw5nf pred: bw5nf\n",
            "label: nxf2c pred: nxf2c\n",
            "label: yyg5g pred: yyg5g\n",
            "label: 62fgn pred: 62fgn\n",
            "label: cfc56 pred: cfc56\n",
            "label: 8g4yp pred: 8g4yp\n",
            "label: yf28d pred: yf28d\n",
            "label: 6g45w pred: 6g45w\n",
            "label: 4w6mw pred: 4w6mw\n",
            "label: nfcwy pred: nfcwy\n",
            "label: gng6e pred: gng6e\n",
            "label: 6cwxe pred: 6cwxe\n",
            "label: e2d66 pred: e2d66\n",
            "label: ep85x pred: ep85x\n",
            "label: wmpmp pred: wmpmp\n",
            "label: w6pxy pred: w6pxy\n",
            "label: xnfx5 pred: xnfx5\n",
            "label: 7wyp4 pred: 7wyp4\n",
            "label: gecmf pred: gecmf\n",
            "label: 4m2w5 pred: 4m2w5\n",
            "label: n8wxm pred: n8wxm\n",
            "label: cdcb3 pred: cdcb3\n",
            "label: n6xc5 pred: n6xc5\n",
            "label: f75cx pred: f75cx\n",
            "label: 77387 pred: 77387\n",
            "label: 85pew pred: 85pew\n",
            "label: nny5e pred: nny5e\n",
            "label: y5w28 pred: y5w28\n",
            "label: 33p4e pred: 33p4e\n",
            "label: 5ep3n pred: 5ep3n\n",
            "label: fwxdp pred: fwxdp\n",
            "label: 23n88 pred: 23n88\n",
            "label: mcyfx pred: mcyfx\n",
            "label: ggd7m pred: ggd7m\n",
            "label: m3wfw pred: m3wfw\n",
            "label: yf347 pred: yf347\n",
            "label: 6gnm3 pred: 6gnm3\n",
            "label: 3nfdn pred: 3nfdn\n",
            "label: x7422 pred: x7422\n",
            "label: e667x pred: e667x\n",
            "label: g842c pred: g842c\n",
            "label: dgcm4 pred: dgcm4\n",
            "label: 243mm pred: 243mm\n",
            "label: nnf8b pred: nnf8b\n",
            "label: 5nm6d pred: 5nm6d\n",
            "label: d666m pred: d666m\n",
            "label: gn2xy pred: gn2xy\n",
            "label: 5mf7c pred: 5mf7c\n",
            "label: 7cgym pred: 7cgym\n",
            "label: e84n2 pred: e84n2\n",
            "label: gnbde pred: gnbde\n",
            "label: 8gecm pred: 8gecm\n",
            "label: m2nf4 pred: m2nf4\n",
            "label: 55y2m pred: 55y2m\n",
            "label: n6f4b pred: n6f4b\n",
            "label: xbcbx pred: xbcbx\n",
            "label: fnbfw pred: fnbfw\n",
            "label: ygfwe pred: ygfwe\n",
            "label: cwmny pred: cwmny\n",
            "label: d3c8y pred: d3c8y\n",
            "label: 678w3 pred: 678w3\n",
            "label: 3x325 pred: 3x325\n",
            "label: nn6w6 pred: nn6w6\n",
            "label: 658xe pred: 658xe\n",
            "label: 6end3 pred: 6end3\n",
            "label: dfnx4 pred: dfnx4\n",
            "label: 23mdg pred: 23mdg\n",
            "label: c5xne pred: c5xne\n",
            "label: ycmcw pred: ycmcw\n",
            "label: 36nx4 pred: 36nx4\n",
            "label: b685n pred: b685n\n",
            "label: 2mpnn pred: 2mpnn\n",
            "label: 7p852 pred: 7p852\n",
            "label: 7dwx4 pred: 7dwx4\n",
            "label: cfn53 pred: cfn53\n",
            "label: f5cm2 pred: f5cm2\n",
            "label: g7fmc pred: g7fmc\n",
            "label: nb45d pred: nb45d\n",
            "label: xc68n pred: xc68n\n",
            "label: 66wp5 pred: 66wp5\n",
            "label: 38n57 pred: 38n57\n",
            "label: wm47f pred: wm47f\n",
            "label: dnne7 pred: dnne7\n",
            "label: m3588 pred: m3588\n",
            "label: 5expp pred: 5expp\n",
            "label: bp2d4 pred: bp2d4\n",
            "label: neggn pred: neggn\n",
            "label: nxc83 pred: nxc83\n",
            "label: n6nn2 pred: n6nn2\n",
            "label: w46ep pred: w46ep\n",
            "label: g3dy6 pred: g3dy6\n",
            "label: pm47f pred: pm47f\n",
            "label: 34fxm pred: 34fxm\n",
            "label: 8cm46 pred: 8cm46\n",
            "label: bdbb3 pred: bdbb3\n",
            "label: nbf8m pred: nbf8m\n",
            "label: fcne6 pred: fcne6\n",
            "label: pnmxf pred: pnmxf\n",
            "label: 3ny45 pred: 3ny45\n",
            "label: ypp8f pred: ypp8f\n",
            "label: nngxc pred: nngxc\n",
            "label: eng53 pred: eng53\n",
            "label: b4d7c pred: b4d7c\n",
            "label: 4433m pred: 4433m\n",
            "label: w75w8 pred: w75w8\n",
            "label: 2b827 pred: 2b827\n",
            "label: 245y5 pred: 245y5\n",
            "label: 7dgc2 pred: 7dgc2\n",
            "label: mw5p2 pred: mw5p2\n",
            "label: ewyg7 pred: ewyg7\n",
            "label: 6e554 pred: 6e554\n",
            "label: 22d5n pred: 22d5n\n",
            "label: b26nd pred: b26nd\n",
            "label: x7746 pred: x7746\n",
            "label: 68wfd pred: 68wfd\n",
            "label: 7fmcy pred: 7fmcy\n",
            "label: ndg2b pred: ndg2b\n",
            "label: w4x2m pred: w4x2m\n",
            "label: 378e5 pred: 378e5\n",
            "label: ng46m pred: ng46m\n",
            "label: 8xef7 pred: 8xef7\n",
            "label: 5wddw pred: 5wddw\n",
            "label: mggce pred: mggce\n",
            "label: 6mygb pred: 6mygb\n",
            "label: xe6eb pred: xe6eb\n",
            "label: bf52c pred: bf52c\n",
            "label: pdyc8 pred: pdyc8\n",
            "label: 2npg6 pred: 2npg6\n",
            "label: ncfgb pred: ncfgb\n",
            "label: 33n73 pred: 33n73\n",
            "label: 73mnx pred: 73mnx\n",
            "label: gm2c2 pred: gm2c2\n",
            "label: nybcx pred: nybcx\n",
            "label: 675p3 pred: 675p3\n",
            "label: 75pfw pred: 75pfw\n",
            "label: ppx77 pred: ppx77\n",
            "label: 6dd2y pred: 6dd2y\n",
            "label: p2m6n pred: p2m6n\n",
            "label: b4y5x pred: b4y5x\n",
            "label: 5gcd3 pred: 5gcd3\n",
            "label: dmxp8 pred: dmxp8\n",
            "label: nn6mg pred: nn6mg\n",
            "label: b84xc pred: b84xc\n",
            "label: 226md pred: 226md\n",
            "label: ncww7 pred: ncww7\n",
            "label: 85622 pred: 85622\n",
            "label: 3bnyf pred: 3bnyf\n",
            "label: ycnfc pred: ycnfc\n",
            "label: c4bgd pred: c4bgd\n",
            "label: w8bnx pred: w8bnx\n",
            "label: 377xx pred: 377xx\n",
            "label: f5e5e pred: f5e5e\n",
            "label: n7ebx pred: n7ebx\n",
            "label: 5p8fm pred: 5p8fm\n",
            "label: nnn57 pred: nnn57\n",
            "label: 2mg87 pred: 2mg87\n",
            "label: n373n pred: n373n\n",
            "label: xcf88 pred: xcf88\n",
            "label: 478nx pred: 478nx\n",
            "label: mmfm6 pred: mmfm6\n",
            "label: 3p4nn pred: 3p4nn\n",
            "label: g888x pred: g888x\n",
            "label: bc8nf pred: bc8nf\n",
            "label: x37bf pred: x37bf\n",
            "label: e4gd7 pred: e4gd7\n",
            "label: 6f2yc pred: 6f2yc\n",
            "label: 3n7mx pred: 3n7mx\n",
            "label: e6b7y pred: e6b7y\n",
            "label: ec6pm pred: ec6pm\n",
            "label: 8n65n pred: 8n65n\n",
            "label: f6bpw pred: f6bpw\n",
            "label: 25257 pred: 25257\n",
            "label: f8f8g pred: f8f8g\n",
            "label: 574d7 pred: 574d7\n",
            "label: gdng3 pred: gdng3\n",
            "label: 8n2pg pred: 8n2pg\n",
            "label: 4dw3w pred: 4dw3w\n",
            "label: 4w76g pred: 4w76g\n",
            "label: nwg2m pred: nwg2m\n",
            "label: 8bbm4 pred: 8bbm4\n",
            "label: bcwnn pred: bcwnn\n",
            "label: nbfx5 pred: nbfx5\n",
            "label: mdxpn pred: mdxpn\n",
            "label: 5x7x5 pred: 5x7x5\n",
            "label: wye85 pred: wye85\n",
            "label: cwdnx pred: cwdnx\n",
            "label: nw5b2 pred: nw5b2\n",
            "label: c753e pred: c753e\n",
            "label: dd764 pred: dd764\n",
            "label: 2bg48 pred: 2bg48\n",
            "label: 8e32m pred: 8e32m\n",
            "label: 467d5 pred: 467d5\n",
            "label: 6e6pn pred: 6e6pn\n",
            "label: 3w2bw pred: 3w2bw\n",
            "label: xcmbp pred: xcmbp\n",
            "label: bw5ym pred: bw5ym\n",
            "label: d22y5 pred: d22y5\n",
            "label: 36w25 pred: 36w25\n",
            "label: 7gce6 pred: 7gce6\n",
            "label: 325fb pred: 325fb\n",
            "label: ddxpp pred: ddxpp\n",
            "label: 4nnf3 pred: 4nnf3\n",
            "label: f364x pred: f364x\n",
            "label: 6xpme pred: 6xpme\n",
            "label: 2g783 pred: 2g783\n",
            "label: gnf85 pred: gnf85\n",
            "label: 32dnn pred: 32dnn\n",
            "label: e8e5e pred: e8e5e\n",
            "label: 2pfpn pred: 2pfpn\n",
            "label: dnmd8 pred: dnmd8\n",
            "label: dce8y pred: dce8y\n",
            "label: 2n73f pred: 2n73f\n",
            "label: 74853 pred: 74853\n",
            "label: e2mg2 pred: e2mg2\n",
            "label: dn5df pred: dn5df\n",
            "label: fpw76 pred: fpw76\n",
            "label: 2en7g pred: 2en7g\n",
            "label: f35xp pred: f35xp\n",
            "label: nb267 pred: nb267\n",
            "label: ydg8n pred: ydg8n\n",
            "label: 6b46g pred: 6b46g\n",
            "label: m74dm pred: m74dm\n",
            "label: ywn6f pred: ywn6f\n",
            "label: 65nmw pred: 65nmw\n",
            "label: w4cnn pred: w4cnn\n",
            "label: c482b pred: c482b\n",
            "label: pp546 pred: pp546\n",
            "label: gd4mf pred: gd4mf\n",
            "label: n7g4f pred: n7g4f\n",
            "label: de45x pred: de45x\n",
            "label: 2ycn8 pred: 2ycn8\n",
            "label: xe8xm pred: xe8xm\n",
            "label: 24f6w pred: 24f6w\n",
            "label: bmxpe pred: bmxpe\n",
            "label: wce5n pred: wce5n\n",
            "label: nwfde pred: nwfde\n",
            "label: 34pcn pred: 34pcn\n",
            "label: dn2ym pred: dn2ym\n",
            "label: 3bx86 pred: 3bx86\n",
            "label: nd5wg pred: nd5wg\n",
            "label: 445cc pred: 445cc\n",
            "label: 2g7nm pred: 2g7nm\n",
            "label: xf4p4 pred: xf4p4\n",
            "label: bwmee pred: bwmee\n",
            "label: xngxc pred: xngxc\n",
            "label: 3c7de pred: 3c7de\n",
            "label: nbwnn pred: nbwnn\n",
            "label: cfw6e pred: cfw6e\n",
            "label: dbfen pred: dbfen\n",
            "label: c6we6 pred: c6we6\n",
            "label: wfy5m pred: wfy5m\n",
            "label: w48cw pred: w48cw\n",
            "label: dn26n pred: dn26n\n",
            "label: n4xx5 pred: n4xx5\n",
            "label: y33nm pred: y33nm\n",
            "label: nxxf8 pred: nxxf8\n",
            "label: mmg38 pred: mmg38\n",
            "label: cewnm pred: cewnm\n",
            "label: 8npd5 pred: 8npd5\n",
            "label: 5pm6b pred: 5pm6b\n",
            "label: yf424 pred: yf424\n",
            "label: 87nym pred: 87nym\n",
            "label: gxx2p pred: gxx2p\n",
            "label: 85dxn pred: 85dxn\n",
            "label: x3deb pred: x3deb\n",
            "label: pmg55 pred: pmg55\n",
            "label: wgnwp pred: wgnwp\n",
            "label: pw5nc pred: pw5nc\n",
            "label: 82fx2 pred: 82fx2\n",
            "label: m8m4x pred: m8m4x\n",
            "label: 53wp3 pred: 53wp3\n",
            "label: m22e3 pred: m22e3\n",
            "label: bp6mw pred: bp6mw\n",
            "label: 5x5nx pred: 5x5nx\n",
            "label: 2nbc5 pred: 2nbc5\n",
            "label: 43p5d pred: 43p5d\n",
            "label: fw3b2 pred: fw3b2\n",
            "label: 8ypdn pred: 8ypdn\n",
            "label: wb3ed pred: wb3ed\n",
            "label: gny6b pred: gny6b\n",
            "label: n7enn pred: n7enn\n",
            "label: d378n pred: d378n\n",
            "label: 42nxy pred: 42nxy\n",
            "label: ne325 pred: ne325\n",
            "label: 8nbew pred: 8nbew\n",
            "label: n265y pred: n265y\n",
            "label: 7pn5g pred: 7pn5g\n",
            "label: nfd8g pred: nfd8g\n",
            "label: d7nn3 pred: d7nn3\n",
            "label: wd2gb pred: wd2gb\n",
            "label: pme86 pred: pme86\n",
            "label: deneb pred: deneb\n",
            "label: d7en3 pred: d7en3\n",
            "label: 4n3mn pred: 4n3mn\n",
            "label: dpbyd pred: dpbyd\n",
            "label: wwmn6 pred: wwmn6\n",
            "label: c4mcm pred: c4mcm\n",
            "label: cdfen pred: cdfen\n",
            "label: c6f8g pred: c6f8g\n",
            "label: ffd6p pred: ffd6p\n",
            "label: g6n7x pred: g6n7x\n",
            "label: c353e pred: c353e\n",
            "label: 6p7gx pred: 6p7gx\n",
            "label: 7y2x4 pred: 7y2x4\n",
            "label: n5n8b pred: n5n8b\n",
            "label: cen55 pred: cen55\n",
            "label: 56ncx pred: 56ncx\n",
            "label: w7e6m pred: w7e6m\n",
            "label: 33f7m pred: 33f7m\n",
            "label: cy3nw pred: cy3nw\n",
            "label: 2nbcx pred: 2nbcx\n",
            "label: 6ydyp pred: 6ydyp\n",
            "label: 3wnd3 pred: 3wnd3\n",
            "label: mx8bb pred: mx8bb\n",
            "label: m5ym2 pred: m5ym2\n",
            "label: ecd4w pred: ecd4w\n",
            "label: xbem6 pred: xbem6\n",
            "label: n4cpy pred: n4cpy\n",
            "label: gbxyy pred: gbxyy\n",
            "label: 832f3 pred: 832f3\n",
            "label: 5n732 pred: 5n732\n",
            "label: 65m85 pred: 65m85\n",
            "label: b35f6 pred: b35f6\n",
            "label: gmmne pred: gmmne\n",
            "label: 84py4 pred: 84py4\n",
            "label: ef4mn pred: ef4mn\n",
            "label: 4ycex pred: 4ycex\n",
            "label: een23 pred: een23\n",
            "label: 72m6f pred: 72m6f\n",
            "label: ny3nn pred: ny3nn\n",
            "label: deep5 pred: deep5\n",
            "label: 6xen4 pred: 6xen4\n",
            "label: p8c24 pred: p8c24\n",
            "label: wnpec pred: wnpec\n",
            "label: yfdn7 pred: yfdn7\n",
            "label: 5bnd7 pred: 5bnd7\n",
            "label: 646x8 pred: 646x8\n",
            "label: fyfbn pred: fyfbn\n",
            "label: 56m6y pred: 56m6y\n",
            "label: nwncn pred: nwncn\n",
            "label: x5f54 pred: x5f54\n",
            "label: nf8b8 pred: nf8b8\n",
            "label: mcg43 pred: mcg43\n",
            "label: fp762 pred: fp762\n",
            "label: 6825y pred: 6825y\n",
            "label: c4bny pred: c4bny\n",
            "label: 8wy7d pred: 8wy7d\n",
            "label: cgcgb pred: cgcgb\n",
            "label: fc6xb pred: fc6xb\n",
            "label: ydd3g pred: ydd3g\n",
            "label: wdww8 pred: wdww8\n",
            "label: cfp86 pred: cfp86\n",
            "label: 7w67m pred: 7w67m\n",
            "label: bnc5f pred: bnc5f\n",
            "label: 6cm6m pred: 6cm6m\n",
            "label: gewfy pred: gewfy\n",
            "label: 4cn7b pred: 4cn7b\n",
            "label: p4nm4 pred: p4nm4\n",
            "label: e6m6p pred: e6m6p\n",
            "label: 2p2y8 pred: 2p2y8\n",
            "label: n336e pred: n336e\n",
            "label: b3xpn pred: b3xpn\n",
            "label: y2xg4 pred: y2xg4\n",
            "label: 3ebpw pred: 3ebpw\n",
            "label: nmy2x pred: nmy2x\n",
            "label: 76353 pred: 76353\n",
            "label: 5xwcg pred: 5xwcg\n",
            "label: 43gey pred: 43gey\n",
            "label: 6p2ge pred: 6p2ge\n",
            "label: mgw3n pred: mgw3n\n",
            "label: x44n4 pred: x44n4\n",
            "label: 8nn73 pred: 8nn73\n",
            "label: wxcn8 pred: wxcn8\n",
            "label: 5mcy7 pred: 5mcy7\n",
            "label: xnd3y pred: xnd3y\n",
            "label: y4ec2 pred: y4ec2\n",
            "label: yw667 pred: yw667\n",
            "label: 6ng6n pred: 6ng6n\n",
            "label: gfp54 pred: gfp54\n",
            "label: cb8cf pred: cb8cf\n",
            "label: nxn4f pred: nxn4f\n",
            "label: gnc3n pred: gnc3n\n",
            "label: 88y52 pred: 88y52\n",
            "label: 6fgdw pred: 6fgdw\n",
            "label: 44xe8 pred: 44xe8\n",
            "label: cd6p4 pred: cd6p4\n",
            "label: pwn5e pred: pwn5e\n",
            "label: e7nx4 pred: e7nx4\n",
            "label: y3c58 pred: y3c58\n",
            "label: 5ng6e pred: 5ng6e\n",
            "label: 6ng6w pred: 6ng6w\n",
            "label: d8dce pred: d8dce\n",
            "label: fy2nd pred: fy2nd\n",
            "label: 7wn74 pred: 7wn74\n",
            "label: p8wwf pred: p8wwf\n",
            "label: bgxcd pred: bgxcd\n",
            "label: x458w pred: x458w\n",
            "label: 8n34n pred: 8n34n\n",
            "label: pgwnp pred: pgwnp\n",
            "label: gy433 pred: gy433\n",
            "label: dbpcd pred: dbpcd\n",
            "label: 5fyem pred: 5fyem\n",
            "label: nm46n pred: nm46n\n",
            "label: ee8fg pred: ee8fg\n",
            "label: m448b pred: m448b\n",
            "label: n3bm6 pred: n3bm6\n",
            "label: 28x47 pred: 28x47\n",
            "label: fxpw3 pred: fxpw3\n",
            "label: 7f8b3 pred: 7f8b3\n",
            "label: bpwd7 pred: bpwd7\n",
            "label: c86md pred: c86md\n",
            "label: nbp3e pred: nbp3e\n",
            "label: x775w pred: x775w\n",
            "label: x277e pred: x277e\n",
            "label: yge7c pred: yge7c\n",
            "label: dxwcw pred: dxwcw\n",
            "label: 4exnn pred: 4exnn\n",
            "label: pdcp4 pred: pdcp4\n",
            "label: 63824 pred: 63824\n",
            "label: 4c8n8 pred: 4c8n8\n",
            "label: nbmx7 pred: nbmx7\n",
            "label: 3nnpw pred: 3nnpw\n",
            "label: ewnx8 pred: ewnx8\n",
            "label: 2wx73 pred: 2wx73\n",
            "label: cdf77 pred: cdf77\n",
            "label: 57b27 pred: 57b27\n",
            "label: mm3nn pred: mm3nn\n",
            "label: ccn2x pred: ccn2x\n",
            "label: m4g8g pred: m4g8g\n",
            "label: xxbm5 pred: xxbm5\n",
            "label: cm6yb pred: cm6yb\n",
            "label: d3ycn pred: d3ycn\n",
            "label: mxnw4 pred: mxnw4\n",
            "label: ngn26 pred: ngn26\n",
            "label: ef4np pred: ef4np\n",
            "label: d2ycw pred: d2ycw\n",
            "label: excmn pred: excmn\n",
            "label: pym7p pred: pym7p\n",
            "label: 537nf pred: 537nf\n",
            "label: xgcxy pred: xgcxy\n",
            "label: b6f2p pred: b6f2p\n",
            "label: 5mnpd pred: 5mnpd\n",
            "label: yw7ny pred: yw7ny\n",
            "label: y32yy pred: y32yy\n",
            "label: b4ndb pred: b4ndb\n",
            "label: befbd pred: befbd\n",
            "label: wc2bd pred: wc2bd\n",
            "label: 5dxnm pred: 5dxnm\n",
            "label: 5xd2e pred: 5xd2e\n",
            "label: 43xfe pred: 43xfe\n",
            "label: cnmnn pred: cnmnn\n",
            "label: 8n5pn pred: 8n5pn\n",
            "label: nnp4e pred: nnp4e\n",
            "label: 264m5 pred: 264m5\n",
            "label: n3x4c pred: n3x4c\n",
            "label: f83pn pred: f83pn\n",
            "label: y866y pred: y866y\n",
            "label: yd38e pred: yd38e\n",
            "label: mwxwp pred: mwxwp\n",
            "label: yxd7m pred: yxd7m\n",
            "label: e72cd pred: e72cd\n",
            "label: d6fcn pred: d6fcn\n",
            "label: 8cccc pred: 8cccc\n",
            "label: be6np pred: be6np\n",
            "label: ncyx8 pred: ncyx8\n",
            "label: 58pnp pred: 58pnp\n",
            "label: 4743p pred: 4743p\n",
            "label: 8c2wy pred: 8c2wy\n",
            "label: mmg2m pred: mmg2m\n",
            "label: dy3cx pred: dy3cx\n",
            "label: bbymy pred: bbymy\n",
            "label: 3ye2e pred: 3ye2e\n",
            "label: ddpyb pred: ddpyb\n",
            "label: f4fn2 pred: f4fn2\n",
            "label: n5x2n pred: n5x2n\n",
            "label: 268g2 pred: 268g2\n",
            "label: edg3p pred: edg3p\n",
            "label: wyc25 pred: wyc25\n",
            "label: w52fn pred: w52fn\n",
            "label: e25xg pred: e25xg\n",
            "label: d75b5 pred: d75b5\n",
            "label: efx34 pred: efx34\n",
            "label: w4cdc pred: w4cdc\n",
            "label: 7634y pred: 7634y\n",
            "label: x2cnn pred: x2cnn\n",
            "label: b2nen pred: b2nen\n",
            "label: 8684m pred: 8684m\n",
            "label: xwx7d pred: xwx7d\n",
            "label: 6n443 pred: 6n443\n",
            "label: d236n pred: d236n\n",
            "label: x38fn pred: x38fn\n",
            "label: fgb36 pred: fgb36\n",
            "label: g7gnf pred: g7gnf\n",
            "label: 7dyww pred: 7dyww\n",
            "label: 7mgmf pred: 7mgmf\n",
            "label: 68x48 pred: 68x48\n",
            "label: d4n82 pred: d4n82\n",
            "label: 42xpy pred: 42xpy\n",
            "label: gy8xb pred: gy8xb\n",
            "label: m23bp pred: m23bp\n",
            "label: gw53m pred: gw53m\n",
            "label: 6mege pred: 6mege\n",
            "label: byc82 pred: byc82\n",
            "label: ny8np pred: ny8np\n",
            "label: nfg23 pred: nfg23\n",
            "label: 5yxgp pred: 5yxgp\n",
            "label: 7m8px pred: 7m8px\n",
            "label: p8ngx pred: p8ngx\n",
            "label: 387g2 pred: 387g2\n",
            "label: nfbg8 pred: nfbg8\n",
            "label: d8xcn pred: d8xcn\n",
            "label: 2gyb6 pred: 2gyb6\n",
            "label: 8pfxx pred: 8pfxx\n",
            "label: 7b4bm pred: 7b4bm\n",
            "label: 4ynf3 pred: 4ynf3\n",
            "label: e46pd pred: e46pd\n",
            "label: 2enf4 pred: 2enf4\n",
            "label: 3bd8f pred: 3bd8f\n",
            "label: y5dpp pred: y5dpp\n",
            "label: 56c34 pred: 56c34\n",
            "label: fcmem pred: fcmem\n",
            "label: nnfx3 pred: nnfx3\n",
            "label: 253dc pred: 253dc\n",
            "label: 77n6g pred: 77n6g\n",
            "label: bgem5 pred: bgem5\n",
            "label: 6mn8n pred: 6mn8n\n",
            "label: ybfx6 pred: ybfx6\n",
            "label: 3bfnd pred: 3bfnd\n",
            "label: n3ffn pred: n3ffn\n",
            "label: pwebm pred: pwebm\n",
            "label: gd8fb pred: gd8fb\n",
            "label: n8fp6 pred: n8fp6\n",
            "label: 8npe3 pred: 8npe3\n",
            "label: 8w754 pred: 8w754\n",
            "label: 24pew pred: 24pew\n",
            "label: 8n56m pred: 8n56m\n",
            "label: fncnb pred: fncnb\n",
            "label: bm3p8 pred: bm3p8\n",
            "label: xw465 pred: xw465\n",
            "label: 428b6 pred: 428b6\n",
            "label: g8gnd pred: g8gnd\n",
            "label: egxmp pred: egxmp\n",
            "label: n2gmg pred: n2gmg\n",
            "label: 6pwcn pred: 6pwcn\n",
            "label: 2wc38 pred: 2wc38\n",
            "label: bnc2f pred: bnc2f\n",
            "label: d7c5x pred: d7c5x\n",
            "label: 8gf7n pred: 8gf7n\n",
            "label: 8d4wm pred: 8d4wm\n",
            "label: neecd pred: neecd\n",
            "label: n8pfe pred: n8pfe\n",
            "label: 7gmf3 pred: 7gmf3\n",
            "label: w6ny4 pred: w6ny4\n",
            "label: 53wb8 pred: 53wb8\n",
            "label: ddcdd pred: ddcdd\n",
            "label: 44c22 pred: 44c22\n",
            "label: g78gn pred: g78gn\n",
            "label: x4gg5 pred: x4gg5\n",
            "label: c7nn8 pred: c7nn8\n",
            "label: c4527 pred: c4527\n",
            "label: d22n7 pred: d22n7\n",
            "label: 67dey pred: 67dey\n",
            "label: 677g3 pred: 677g3\n",
            "label: myf82 pred: myf82\n",
            "label: yd3m3 pred: yd3m3\n",
            "label: 7xcyd pred: 7xcyd\n",
            "label: wf684 pred: wf684\n",
            "label: p5g5m pred: p5g5m\n",
            "label: 5npdn pred: 5npdn\n",
            "label: wddcp pred: wddcp\n",
            "label: fg8n4 pred: fg8n4\n",
            "label: 573bn pred: 573bn\n",
            "label: yg5bb pred: yg5bb\n",
            "label: pwmbn pred: pwmbn\n",
            "label: 8gmc4 pred: 8gmc4\n",
            "label: mfc35 pred: mfc35\n",
            "label: 4cfw8 pred: 4cfw8\n",
            "label: 7nnnx pred: 7nnnx\n",
            "label: gp7c5 pred: gp7c5\n",
            "label: e3cfe pred: e3cfe\n",
            "label: fbp2c pred: fbp2c\n",
            "label: 664dn pred: 664dn\n",
            "label: mxyxw pred: mxyxw\n",
            "label: wxy4n pred: wxy4n\n",
            "label: x8xnp pred: x8xnp\n",
            "label: nbwpn pred: nbwpn\n",
            "label: p57fn pred: p57fn\n",
            "label: 785n4 pred: 785n4\n",
            "label: bgd4m pred: bgd4m\n",
            "label: pgm2e pred: pgm2e\n",
            "label: gc2wd pred: gc2wd\n",
            "label: p4pde pred: p4pde\n",
            "label: efe62 pred: efe62\n",
            "label: g55b4 pred: g55b4\n",
            "label: 88bgx pred: 88bgx\n",
            "label: 662bw pred: 662bw\n",
            "label: cndmc pred: cndmc\n",
            "label: w4nfx pred: w4nfx\n",
            "label: pcpg6 pred: pcpg6\n",
            "label: 2cg58 pred: 2cg58\n",
            "label: pcmcc pred: pcmcc\n",
            "label: 2cegf pred: 2cegf\n",
            "label: gc83b pred: gc83b\n",
            "label: gwn53 pred: gwn53\n",
            "label: ccf2w pred: ccf2w\n",
            "label: ndme7 pred: ndme7\n",
            "label: xfg65 pred: xfg65\n",
            "label: pxne8 pred: pxne8\n",
            "label: 64m82 pred: 64m82\n",
            "label: dbex3 pred: dbex3\n",
            "label: c3n8x pred: c3n8x\n",
            "label: dc436 pred: dc436\n",
            "label: 33ng4 pred: 33ng4\n",
            "label: e5n66 pred: e5n66\n",
            "label: x362g pred: x362g\n",
            "label: f85y3 pred: f85y3\n",
            "label: gw468 pred: gw468\n",
            "label: gfxcc pred: gfxcc\n",
            "label: x4f7g pred: x4f7g\n",
            "label: x3fwf pred: x3fwf\n",
            "label: 2x7bm pred: 2x7bm\n",
            "label: pnnwy pred: pnnwy\n",
            "label: 7xd5m pred: 7xd5m\n",
            "label: ppwyd pred: ppwyd\n",
            "label: mgdwb pred: mgdwb\n",
            "label: mc8w2 pred: mc8w2\n",
            "label: 8n4n8 pred: 8n4n8\n",
            "label: ng756 pred: ng756\n",
            "label: wecfd pred: wecfd\n",
            "label: cg5dd pred: cg5dd\n",
            "label: ncw4g pred: ncw4g\n",
            "label: cd4eg pred: cd4eg\n",
            "label: c2yn8 pred: c2yn8\n",
            "label: p2ym2 pred: p2ym2\n",
            "label: 65ebm pred: 65ebm\n",
            "label: xxney pred: xxney\n",
            "label: gc277 pred: gc277\n",
            "label: f74x3 pred: f74x3\n",
            "label: mddgb pred: mddgb\n",
            "label: 47e4p pred: 47e4p\n",
            "label: ng2gw pred: ng2gw\n",
            "label: 3ym7f pred: 3ym7f\n",
            "label: pbpgc pred: pbpgc\n",
            "label: bny23 pred: bny23\n",
            "label: 823p2 pred: 823p2\n",
            "label: y7x8p pred: y7x8p\n",
            "label: 373gb pred: 373gb\n",
            "label: gwnm6 pred: gwnm6\n",
            "label: myc3c pred: myc3c\n",
            "label: 664nf pred: 664nf\n",
            "label: 5n245 pred: 5n245\n",
            "label: c2g4d pred: c2g4d\n",
            "label: b5pnn pred: b5pnn\n",
            "label: 8n5p3 pred: 8n5p3\n",
            "label: 8n62n pred: 8n62n\n",
            "label: 3d7bd pred: 3d7bd\n",
            "label: fywb8 pred: fywb8\n",
            "label: cpe63 pred: cpe63\n",
            "label: 6fn84 pred: 6fn84\n",
            "label: ffpxf pred: ffpxf\n",
            "label: 6wb76 pred: 6wb76\n",
            "label: xce8d pred: xce8d\n",
            "label: y48c3 pred: y48c3\n",
            "label: 57wdp pred: 57wdp\n",
            "label: 8eggg pred: 8eggg\n",
            "label: 44fyb pred: 44fyb\n",
            "label: n5w5g pred: n5w5g\n",
            "label: md344 pred: md344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyYX7mCt5Qyj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "07e8b643-e779-4c51-8110-71cf0d5dcddb"
      },
      "source": [
        "path = F\"/content/captcharesnet_0.0000.pth\"\n",
        "bestmodel.load_state_dict(torch.load(path))\n",
        "bestmodel=bestmodel.to(device)\n",
        "bestmodel"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-455fe013f186>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mF\"/content/captcharesnet_0.0000.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbestmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbestmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbestmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbestmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'load_state_dict'"
          ]
        }
      ]
    }
  ]
}